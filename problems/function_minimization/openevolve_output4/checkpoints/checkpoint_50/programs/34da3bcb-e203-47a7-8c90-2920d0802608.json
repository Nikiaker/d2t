{"id": "34da3bcb-e203-47a7-8c90-2920d0802608", "code": "# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\nimport random\nfrom scipy.optimize import differential_evolution\n\ndef evaluate_function(x):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x[0]) * np.cos(x[1]) + np.sin(x[0] * x[1]) + (x[0]**2 + x[1]**2) / 20\n\n\ndef search_algorithm(bounds=((-5, 5), (-5, 5)), iterations=1000):\n    \"\"\"\n    A differential evolution algorithm to find the global minimum.\n\n    Args:\n        bounds: Bounds for the search space (min, max)\n        iterations: Number of iterations to run\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Run the differential evolution algorithm with multiple restarts\n    best_x, best_y, best_value = None, None, float('inf')\n    for _ in range(10):\n        result = differential_evolution(evaluate_function, bounds, maxiter=iterations)\n        x, y = result.x\n        value = result.fun\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\ndef generate_multiple_solutions(bounds, iterations, num_solutions):\n    \"\"\"Generate multiple solutions using the search algorithm\"\"\"\n    solutions = []\n    for _ in range(num_solutions):\n        x, y, value = search_algorithm(bounds, iterations)\n        solutions.append((x, y, value))\n    return solutions\n\n\ndef calculate_diversity(solutions):\n    \"\"\"Calculate the diversity of the solutions\"\"\"\n    diversity = 0\n    for i in range(len(solutions)):\n        for j in range(i + 1, len(solutions)):\n            distance = np.sqrt((solutions[i][0] - solutions[j][0])**2 + (solutions[i][1] - solutions[j][1])**2 + (solutions[j][1]\ndef run_search_with_diversity(bounds, iterations, num_solutions = search_algorithm()\n    return x, y, value\n\n\ndef improve_fitness(solutions):\n    \"\"\"Improve the fitness of the solutions by selecting the best solution\"\"\"\n    best_solution = max(solutions, key=lambda x: x[2])\n    return best_solution)\n\n\n# EVOLVE-BLOCK-END\n\n# Your rewritten program here", "language": "python", "parent_id": "6330d97a-726b-4dab-8293-cd09ac328868", "generation": 2, "timestamp": 1762987159.3645399, "iteration_found": 43, "metrics": {"runs_successfully": 0.0, "combined_score": 0.0, "error": "'(' was never closed (tmp2mgvzzjx.py, line 59)"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Full rewrite", "parent_metrics": {"runs_successfully": 1.0, "value_score": 0.9996859395135482, "distance_score": 0.9995011292583302, "combined_score": 1.4995399628014097, "reliability_score": 1.0}, "island": 0}, "prompts": {"full_rewrite_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve a function minimization algorithm to find the global minimum of a complex function with many local minima. The function is f(x, y) = sin(x) * cos(y) + sin(x*y) + (x^2 + y^2)/20. Focus on improving the search_algorithm function to reliably find the global minimum, escaping local minima that might trap simple algorithms.", "user": "# Current Program Information\n- Fitness: 1.4995\n- Feature coordinates: No feature coordinates\n- Focus areas: - Fitness improved: 1.4995 \u2192 1.4995\n- Consider simplifying - code length exceeds 500 characters\n\n## Last Execution Output\n\n### stage1_result\n```\nFound solution at x=-1.7041, y=0.6775 with value=-1.5187\n```\n\n### distance_to_global\n```\n0.0005\n```\n\n### solution_quality\n```\nDistance < 0.5: Very close\n```\n\n### convergence_info\n```\nConverged in 10 trials with 10 successes\n```\n\n### best_position\n```\nFinal position: x=-1.7041, y=0.6775\n```\n\n### average_distance_to_global\n```\n0.0005\n```\n\n### search_efficiency\n```\nSuccess rate: 100.00%\n```\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Full rewrite\n- Metrics: runs_successfully: 1.0000, value_score: 0.9997, distance_score: 0.9995, combined_score: 1.4995, reliability_score: 1.0000\n- Outcome: Mixed results\n\n### Attempt 2\n- Changes: Full rewrite\n- Metrics: runs_successfully: 1.0000, value_score: 0.9997, distance_score: 0.9995, combined_score: 1.4995, reliability_score: 1.0000\n- Outcome: Mixed results\n\n### Attempt 1\n- Changes: Full rewrite\n- Metrics: runs_successfully: 1.0000, value_score: 0.9997, distance_score: 0.9995, combined_score: 1.4995, reliability_score: 1.0000\n- Outcome: Mixed results\n\n## Top Performing Programs\n\n### Program 1 (Score: 1.4995)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\nimport random\nfrom scipy.optimize import differential_evolution\n\ndef evaluate_function(x):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x[0]) * np.cos(x[1]) + np.sin(x[0] * x[1]) + (x[0]**2 + x[1]**2) / 20\n\n\ndef search_algorithm(bounds=((-5, 5), (-5, 5)), iterations=1000):\n    \"\"\"\n    A differential evolution algorithm to find the global minimum.\n\n    Args:\n        bounds: Bounds for the search space (min, max)\n        iterations: Number of iterations to run\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Run the differential evolution algorithm\n    result = differential_evolution(evaluate_function, bounds, maxiter=iterations)\n    best_x, best_y = result.x\n    best_value = result.fun\n\n    return best_x, best_y, best_value\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    # Run the search multiple times and keep the best result\n    best_x, best_y, best_value = None, None, float('inf')\n    for _ in range(10):\n        x, y, value = search_algorithm()\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    # Use a more robust random number generator\n    random.seed(42)\n\n    # Increase the number of iterations\n    iterations = 2000\n\n    # Print the result\n    print(f\"Found minimum at ({best_x}, {best_y}) with value {best_value}\")\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9997), Performs well on distance_score (0.9995), Performs well on combined_score (1.4995), Performs well on reliability_score (1.0000)\n\n### Program 2 (Score: 1.4995)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\nimport random\nfrom scipy.optimize import differential_evolution\n\ndef evaluate_function(x):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x[0]) * np.cos(x[1]) + np.sin(x[0] * x[1]) + (x[0]**2 + x[1]**2) / 20\n\n\ndef search_algorithm(bounds=((-5, 5), (-5, 5)), iterations=1000):\n    \"\"\"\n    A differential evolution algorithm to find the global minimum.\n\n    Args:\n        bounds: Bounds for the search space (min, max)\n        iterations: Number of iterations to run\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Run the differential evolution algorithm with multiple restarts\n    best_x, best_y, best_value = None, None, float('inf')\n    for _ in range(10):\n        result = differential_evolution(evaluate_function, bounds, maxiter=iterations)\n        x, y = result.x\n        value = result.fun\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    # Run the search\n    x, y, value = run_search()\n\n    # Print the result\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9997), Performs well on distance_score (0.9995), Performs well on combined_score (1.4995), Performs well on reliability_score (1.0000)\n\n### Program 3 (Score: 1.4995)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\nimport random\nfrom scipy.optimize import differential_evolution\n\ndef evaluate_function(x):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x[0]) * np.cos(x[1]) + np.sin(x[0] * x[1]) + (x[0]**2 + x[1]**2) / 20\n\n\ndef search_algorithm(bounds=((-5, 5), (-5, 5)), iterations=1000):\n    \"\"\"\n    A differential evolution algorithm to find the global minimum.\n\n    Args:\n        bounds: Bounds for the search space (min, max)\n        iterations: Number of iterations to run\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Run the differential evolution algorithm\n    result = differential_evolution(evaluate_function, bounds, maxiter=iterations)\n    best_x, best_y = result.x\n    best_value = result.fun\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\ndef generate_initial_population(population_size, bounds):\n    \"\"\"\n    Generate an initial population of random solutions.\n\n    Args:\n        population_size: Number of solutions to generate\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        List of (x, y) tuples representing the initial population\n    \"\"\"\n    initial_population = []\n    for _ in range(population_size):\n        x = random.uniform(bounds[0], bounds[1])\n        y = random.uniform(bounds[0], bounds[1])\n        initial_population.append((x, y))\n    return initial_population\n\n\ndef mutate_solution(solution, mutation_rate, bounds):\n    \"\"\"\n    Mutate a solution by applying a small random change.\n\n    Args:\n        solution: The solution to mutate (x, y)\n        mutation_rate: Probability of applying a mutation\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        The mutated solution (x, y)\n    \"\"\"\n    x, y = solution\n    if random.random() < mutation_rate:\n        x += random.uniform(-0.1, 0.1)\n        y += random.uniform(-0.1, 0.1)\n        x = max(bounds[0], min(x, bounds[1]))\n        y = max(bounds[0], min(y, bounds[1]))\n    return x, y\n\n\ndef crossover(parent1, parent2):\n    \"\"\"\n    Perform crossover between two parents to produce a child.\n\n    Args:\n        parent1: The first parent (x, y)\n        parent2: The second parent (x, y)\n\n    Returns:\n        The child solution (x, y)\n    \"\"\"\n    x1, y1 = parent1\n    x2, y2 = parent2\n    child_x = (x1 + x2) / 2\n    child_y = (y1 + y2) / 2\n    return child_x, child_y\n\n\ndef search_algorithm_improved(bounds=((-5, 5), (-5, 5)), iterations=1000):\n    \"\"\"\n    An improved version of the search algorithm using a combination of mutation, crossover, and selection.\n\n    Args:\n        bounds: Bounds for the search space (min, max)\n        iterations: Number of iterations to run\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    population_size = 100\n    initial_population = generate_initial_population(population_size, bounds)\n\n    for _ in range(iterations):\n        # Evaluate the fitness of each solution in the population\n        fitnesses = [evaluate_function((x, y)) for x, y in initial_population]\n\n        # Select the fittest solutions to reproduce\n        selected_indices = np.argsort(fitnesses)[:int(population_size / 2)]\n        selected_solutions = [(x, y) for i, (x, y) in enumerate(initial_population) if i in selected_indices]\n\n        # Perform crossover to produce new offspring\n        offspring = []\n        for i in range(int(population_size / 2)):\n            parent1, parent2 = random.sample(selected_solutions, 2)\n            child = crossover(parent1, parent2)\n            offspring.append(child)\n\n        # Mutate the offspring to introduce random changes\n        mutated_offspring = []\n        for i, child in enumerate(offspring):\n            mutated_child = mutate_solution(child, 0.1, bounds)\n            mutated_offspring.append(mutated_child)\n\n        # Replace the least fit solutions with the new offspring\n        sorted_indices = np.argsort(fitnesses)\n        least_fit_indices = sorted_indices[-int(population_size / 2):]\n        initial_population = [(x, y) for i, (x, y) in enumerate(initial_population) if i not in least_fit_indices]\n        initial_population.extend(mutated_offspring)\n\n    # Evaluate the fitness of each solution in the final population\n    fitnesses = [evaluate_function((x, y)) for x, y in initial_population]\n\n    # Return the solution with the best fitness\n    best_index = np.argmin(fitnesses)\n    best_x, best_y = initial_population[best_index]\n    best_value = fitnesses[best_index]\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\nif __name__ == \"__main__\":\n    x, y, value = search_algorithm_improved()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9997), Performs well on distance_score (0.9995), Performs well on combined_score (1.4995), Performs well on reliability_score (1.0000)\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 1.4995)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\nimport random\nfrom scipy.optimize import differential_evolution\n\ndef evaluate_function(x):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x[0]) * np.cos(x[1]) + np.sin(x[0] * x[1]) + (x[0]**2 + x[1]**2) / 20\n\n\ndef search_algorithm(bounds=((-5, 5), (-5, 5)), iterations=1000):\n    \"\"\"\n    A differential evolution algorithm to find the global minimum.\n\n    Args:\n        bounds: Bounds for the search space (min, max)\n        iterations: Number of iterations to run\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Run the differential evolution algorithm\n    result = differential_evolution(evaluate_function, bounds, maxiter=iterations)\n    best_x, best_y = result.x\n    best_value = result.fun\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\ndef generate_multiple_solutions(bounds, iterations, num_solutions):\n    \"\"\"Generate multiple solutions using the search algorithm\"\"\"\n    solutions = []\n    for _ in range(num_solutions):\n        x, y, value = search_algorithm(bounds, iterations)\n        solutions.append((x, y, value))\n    return solutions\n\n\ndef calculate_diversity(solutions):\n    \"\"\"Calculate the diversity of the solutions\"\"\"\n    diversity = 0\n    for i in range(len(solutions)):\n        for j in range(i + 1, len(solutions)):\n            distance = np.sqrt((solutions[i][0] - solutions[j][0])**2 + (solutions[i][1] - solutions[j][1])**2)\n            diversity += 1 / (1 + distance)\n    return diversity\n\n\ndef improve_fitness(solutions):\n    \"\"\"Improve the fitness of the solutions by selecting the best one\"\"\"\n    best_solution = max(solutions, key=lambda x: x[2])\n    return best_solution\n\n\ndef run_search_with_diversity(bounds, iterations, num_solutions):\n    \"\"\"Run the search algorithm with diversity\"\"\"\n    solutions = generate_multiple_solutions(bounds, iterations, num_solutions)\n    diversity = calculate_diversity(solutions)\n    best_solution = improve_fitness(solutions)\n    return best_solution\n\n\nif __name__ == \"__main__\":\n    # Run the search with diversity\n    x, y, value = run_search_with_diversity((-5, 5), 1000, 10)\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to value_score\n\n### Program D2 (Score: 1.4995)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\nimport random\nfrom scipy.optimize import differential_evolution\n\ndef evaluate_function(x):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x[0]) * np.cos(x[1]) + np.sin(x[0] * x[1]) + (x[0]**2 + x[1]**2) / 20\n\n\ndef search_algorithm(bounds=((-5, 5), (-5, 5)), iterations=1000):\n    \"\"\"\n    A differential evolution algorithm to find the global minimum.\n\n    Args:\n        bounds: Bounds for the search space (min, max)\n        iterations: Number of iterations to run\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Run the differential evolution algorithm\n    result = differential_evolution(evaluate_function, bounds, maxiter=iterations)\n    best_x, best_y = result.x\n    best_value = result.fun\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    # Run the search\n    x, y, value = run_search()\n\n    # Print the result\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to value_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 1.4995, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\nimport random\nfrom scipy.optimize import differential_evolution\n\ndef evaluate_function(x):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x[0]) * np.cos(x[1]) + np.sin(x[0] * x[1]) + (x[0]**2 + x[1]**2) / 20\n\n\ndef search_algorithm(bounds=((-5, 5), (-5, 5)), iterations=1000):\n    \"\"\"\n    A differential evolution algorithm to find the global minimum.\n\n    Args:\n        bounds: Bounds for the search space (min, max)\n        iterations: Number of iterations to run\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Run the differential evolution algorithm\n    result = differential_evolution(evaluate_function, bounds, maxiter=iterations)\n    best_x, best_y = result.x\n    best_value = result.fun\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    # Run the search\n    x, y, value = run_search()\n\n    # Print the result\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n```\nUnique approach: Modification: Full rewrite, Excellent runs_successfully (1.000), Excellent value_score (1.000)\n\n### Inspiration 2 (Score: 0.2915, Type: Exploratory)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A simple random search algorithm that often gets stuck in local minima.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    best_x = 0\n    best_y = 0\n    best_value = evaluate_function(best_x, best_y)\n\n    for _ in range(iterations):\n        # Simple random search\n        x = best_x + 1\n        y = best_y - 1\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Excellent runs_successfully (1.000), Alternative distance_score approach, Alternative combined_score approach\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\nimport random\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5):\n    \"\"\"\n    A multi-start random search algorithm with restarts to escape local minima\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space min max\n\n    Returns:\n        Tuple of (best_x, best_y, best_value\n\"\"\"\n# Initialize with a random point\nbest_x = random.uniform(bounds[0], bounds[1])\nbest_y = random.uniform(bounds[0], bounds[1])\nbest_value = evaluate_function(best_x, best_y)\n\n# Multi-start random search with restarts\nfor _ in range(iterations):\n    # Simple random search\nx = random.uniform(bounds[0], bounds[1])\ny = random.uniform(bounds[0], bounds[1])\nvalue = evaluate_function(x, y)\n\"\"\"\nnp.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    best_x = random.uniform(bounds[0], bounds[1])\n    best_y = random.uniform(bounds[0], bounds[1])\n    best_value = evaluate_function(best_x, best_y)\n\n    # Multi-start random search with restarts\n    for _ in range(iterations):\n        # Simple random search\n        x = random.uniform(bounds[0], bounds[1])\n        y = random.uniform(bounds[0], bounds[1])\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n            best_value = best_x, best_y = x, y\n\n\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\n# This remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\"\n```\nUnique approach: Modification: Full rewrite, Alternative runs_successfully approach, Alternative combined_score approach\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\nimport random\nfrom scipy.optimize import differential_evolution\n\ndef evaluate_function(x):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x[0]) * np.cos(x[1]) + np.sin(x[0] * x[1]) + (x[0]**2 + x[1]**2) / 20\n\n\ndef search_algorithm(bounds=((-5, 5), (-5, 5)), iterations=1000):\n    \"\"\"\n    A differential evolution algorithm to find the global minimum.\n\n    Args:\n        bounds: Bounds for the search space (min, max)\n        iterations: Number of iterations to run\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Run the differential evolution algorithm with multiple restarts\n    best_x, best_y, best_value = None, None, float('inf')\n    for _ in range(10):\n        result = differential_evolution(evaluate_function, bounds, maxiter=iterations)\n        x, y = result.x\n        value = result.fun\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    # Run the search\n    x, y, value = run_search()\n\n    # Print the result\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n```\n\n# Task\nRewrite the program to improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\nProvide the complete new program code.\n\nIMPORTANT: Make sure your rewritten program maintains the same inputs and outputs\nas the original program, but with improved internal implementation.\n\n```python\n# Your rewritten program here\n```", "responses": ["```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\nimport random\nfrom scipy.optimize import differential_evolution\n\ndef evaluate_function(x):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x[0]) * np.cos(x[1]) + np.sin(x[0] * x[1]) + (x[0]**2 + x[1]**2) / 20\n\n\ndef search_algorithm(bounds=((-5, 5), (-5, 5)), iterations=1000):\n    \"\"\"\n    A differential evolution algorithm to find the global minimum.\n\n    Args:\n        bounds: Bounds for the search space (min, max)\n        iterations: Number of iterations to run\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Run the differential evolution algorithm with multiple restarts\n    best_x, best_y, best_value = None, None, float('inf')\n    for _ in range(10):\n        result = differential_evolution(evaluate_function, bounds, maxiter=iterations)\n        x, y = result.x\n        value = result.fun\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\ndef generate_multiple_solutions(bounds, iterations, num_solutions):\n    \"\"\"Generate multiple solutions using the search algorithm\"\"\"\n    solutions = []\n    for _ in range(num_solutions):\n        x, y, value = search_algorithm(bounds, iterations)\n        solutions.append((x, y, value))\n    return solutions\n\n\ndef calculate_diversity(solutions):\n    \"\"\"Calculate the diversity of the solutions\"\"\"\n    diversity = 0\n    for i in range(len(solutions)):\n        for j in range(i + 1, len(solutions)):\n            distance = np.sqrt((solutions[i][0] - solutions[j][0])**2 + (solutions[i][1] - solutions[j][1])**2 + (solutions[j][1]\ndef run_search_with_diversity(bounds, iterations, num_solutions = search_algorithm()\n    return x, y, value\n\n\ndef improve_fitness(solutions):\n    \"\"\"Improve the fitness of the solutions by selecting the best solution\"\"\"\n    best_solution = max(solutions, key=lambda x: x[2])\n    return best_solution)\n\n\n# EVOLVE-BLOCK-END\n\n# Your rewritten program here\n```python\n# EVOLVE-BLOCK-START\nimport numpy as np\nimport random from scipy.optimize import differential_evolution\ndef evaluate_function(x):\n    return np.sin(x[0] * np.cos(x[1]) + np.sin(x[0 * x[1]) + (x[0]2 + x[1]2 / 20\n\n\ndef search_algorithm(bounds=((-5, 5), (-5, 5), iterations=1000):\n    \"\"\"\n    A differential evolution algorithm to find the global minimum.\n\n    Args:\n        bounds: Bounds for the search space (min, max)\n        iterations: Number of iterations to run\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Run the differential evolution algorithm\n    result = differential_evolution(evaluate_function, bounds, maxiter=iterations)\n    best_x, best_y = result.x\n    best_value = result.fun\n\n    return best_x, best_y, best_value\n\n\ndef generate_multiple_solutions(bounds, iterations, num_solutions):\n    \"\"\"Generate multiple solutions using the search algorithm\"\"\"\n    solutions = []\n    for _ in range(num_solutions):\n        x, y, value = search_algorithm(bounds, iterations)\n        solutions.append((x, y, value))\n    return solutions\n\n\ndef calculate_diversity(solutions):\n    \"\"\"Calculate the diversity of the solutions\"\"\"\n    diversity = 0\n    for i in range(len(solutions)):\n        for j in range(i + 1, len(solutions)):\n            distance = np.sqrt((solutions[i][0] - solutions[j][0])**2 + (solutions[i][1] - solutions[j][1])**2)\n            diversity += 1 / (1 + distance)\n    return diversity\n\n\ndef improve_fitness(solutions):\n    \"\"\"Improve the fitness of the solutions by selecting the best one\"\"\"\n    best_solution = max(solutions, key=lambda x: x[2])\n    return best_solution\n\n\ndef run_search_with_diversity(bounds, iterations, num_solutions):\n    \"\"\"Run the search algorithm with diversity\"\"\"\n    solutions = generate_multiple_solutions(bounds, iterations, num_solutions)\n    diversity = calculate_diversity(solutions)\n    best_solution = improve_fitness(solutions)\n    return best_solution\n\n\nif __name__ == \"__main__\":\n    # Run the search with diversity\n    x, y, value = run_search_with_diversity((-5, 5), 1000, 10)\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n```\n\n```"]}}, "artifacts_json": "{\"error_type\": \"SyntaxError\", \"error_message\": \"Stage 1 outer exception: '(' was never closed (tmp2mgvzzjx.py, line 59)\", \"full_traceback\": \"Traceback (most recent call last):\\n  File \\\"/home/nikiaker/Projects/studia/stop2/magisterka/d2t/problems/function_minimization/evaluator.py\\\", line 271, in evaluate_stage1\\n    spec.loader.exec_module(program)\\n  File \\\"<frozen importlib._bootstrap_external>\\\", line 995, in exec_module\\n  File \\\"<frozen importlib._bootstrap_external>\\\", line 1133, in get_code\\n  File \\\"<frozen importlib._bootstrap_external>\\\", line 1063, in source_to_code\\n  File \\\"<frozen importlib._bootstrap>\\\", line 488, in _call_with_frames_removed\\n  File \\\"/tmp/nix-shell-199440-0/tmp2mgvzzjx.py\\\", line 59\\n    distance = np.sqrt((solutions[i][0] - solutions[j][0])**2 + (solutions[i][1] - solutions[j][1])**2 + (solutions[j][1]\\n                                                                                                         ^\\nSyntaxError: '(' was never closed\\n\", \"suggestion\": \"Critical error during stage 1 evaluation. Check program syntax and imports\"}", "artifact_dir": null, "embedding": null}