2025-11-12 23:28:10,317 - openevolve.controller - INFO - Logging to openevolve_output/logs/openevolve_20251112_232810.log
2025-11-12 23:28:10,322 - openevolve.controller - INFO - Set random seed to 42 for reproducibility
2025-11-12 23:28:10,356 - openevolve.llm.openai - INFO - Initialized OpenAI LLM with model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:28:10,357 - openevolve.llm.ensemble - INFO - Initialized LLM ensemble with models: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8 (weight: 1.00)
2025-11-12 23:28:10,373 - openevolve.prompt.sampler - INFO - Initialized prompt sampler
2025-11-12 23:28:10,373 - openevolve.prompt.sampler - INFO - Set custom templates: system=evaluator_system_message, user=None
2025-11-12 23:28:10,374 - openevolve.database - INFO - Initialized program database with 0 programs
2025-11-12 23:28:10,374 - openevolve.evaluator - INFO - Successfully loaded evaluation function from evaluator.py
2025-11-12 23:28:10,374 - openevolve.evaluator - INFO - Initialized evaluator with evaluator.py
2025-11-12 23:28:10,374 - openevolve.controller - INFO - Initialized OpenEvolve with initial_program.py
2025-11-12 23:28:10,374 - openevolve.controller - INFO - Adding initial program to database
2025-11-12 23:28:10,380 - openevolve.evaluator - INFO - Evaluated program dc9bbfb0-2163-4b65-829f-585943ba5fd3 in 0.01s: runs_successfully=1.0000, value_score=0.4480, distance_score=0.2391, combined_score=0.2915
2025-11-12 23:28:10,380 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 5, 'diversity': 0}
2025-11-12 23:28:10,381 - openevolve.process_parallel - INFO - Initialized process parallel controller with 3 workers
2025-11-12 23:28:10,381 - openevolve.process_parallel - INFO - Started process pool with 3 processes
2025-11-12 23:28:10,381 - openevolve.controller - INFO - Using island-based evolution with 3 islands
2025-11-12 23:28:10,381 - openevolve.database - INFO - Island Status:
2025-11-12 23:28:10,381 - openevolve.database - INFO -  * Island 0: 1 programs, best=0.2915, avg=0.2915, diversity=0.00, gen=0 (best: dc9bbfb0-2163-4b65-829f-585943ba5fd3)
2025-11-12 23:28:10,381 - openevolve.database - INFO -    Island 1: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=0
2025-11-12 23:28:10,382 - openevolve.database - INFO -    Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=0
2025-11-12 23:28:10,382 - openevolve.process_parallel - INFO - Starting process-based evolution from iteration 1 for 100 iterations (total: 101)
2025-11-12 23:28:10,387 - openevolve.process_parallel - INFO - Early stopping disabled
2025-11-12 23:28:10,440 - openevolve.prompt.sampler - INFO - Set custom templates: system=evaluator_system_message, user=None
2025-11-12 23:28:10,440 - openevolve.evaluator - INFO - Successfully loaded evaluation function from evaluator.py
2025-11-12 23:28:10,440 - openevolve.evaluator - INFO - Initialized evaluator with evaluator.py
2025-11-12 23:28:10,442 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:28:10,449 - openevolve.prompt.sampler - INFO - Set custom templates: system=evaluator_system_message, user=None
2025-11-12 23:28:10,449 - openevolve.prompt.sampler - INFO - Set custom templates: system=evaluator_system_message, user=None
2025-11-12 23:28:10,450 - openevolve.evaluator - INFO - Successfully loaded evaluation function from evaluator.py
2025-11-12 23:28:10,450 - openevolve.evaluator - INFO - Successfully loaded evaluation function from evaluator.py
2025-11-12 23:28:10,450 - openevolve.evaluator - INFO - Initialized evaluator with evaluator.py
2025-11-12 23:28:10,450 - openevolve.evaluator - INFO - Initialized evaluator with evaluator.py
2025-11-12 23:28:10,451 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:28:10,451 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:28:28,286 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:28:28,317 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:28:28,317 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:28:28,329 - openevolve.evaluator - INFO - Evaluated program 0cc1e0fe-1e97-4bbd-abf9-01bf6ca9cadc in 0.04s: runs_successfully=1.0000, value_score=0.9774, distance_score=0.8866, combined_score=1.4320, reliability_score=1.0000
2025-11-12 23:28:28,330 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:28:28,340 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 9, 'diversity': 5}
2025-11-12 23:28:28,340 - openevolve.database - INFO - New best program 0cc1e0fe-1e97-4bbd-abf9-01bf6ca9cadc replaces dc9bbfb0-2163-4b65-829f-585943ba5fd3 (combined_score: 0.2915 â†’ 1.4320, +1.1405)
2025-11-12 23:28:28,340 - openevolve.process_parallel - INFO - Iteration 2: Program 0cc1e0fe-1e97-4bbd-abf9-01bf6ca9cadc (parent: dc9bbfb0-2163-4b65-829f-585943ba5fd3) completed in 17.88s
2025-11-12 23:28:28,340 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9774, distance_score=0.8866, combined_score=1.4320, reliability_score=1.0000
2025-11-12 23:28:28,340 - openevolve.process_parallel - INFO - ðŸŒŸ New best solution found at iteration 2: 0cc1e0fe-1e97-4bbd-abf9-01bf6ca9cadc
2025-11-12 23:28:28,362 - openevolve.evaluator - INFO - Evaluated program 88aba674-97c5-46fa-a95a-384092721017 in 0.04s: runs_successfully=1.0000, value_score=0.9524, distance_score=0.8116, combined_score=1.3795, reliability_score=1.0000
2025-11-12 23:28:28,362 - openevolve.evaluator - INFO - Evaluated program 00176986-4d82-41a7-b11c-c70752910cb9 in 0.04s: runs_successfully=1.0000, value_score=0.9750, distance_score=0.8726, combined_score=1.4239, reliability_score=1.0000
2025-11-12 23:28:28,363 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:28:28,363 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:28:28,371 - openevolve.process_parallel - INFO - Iteration 1: Program 88aba674-97c5-46fa-a95a-384092721017 (parent: dc9bbfb0-2163-4b65-829f-585943ba5fd3) completed in 17.91s
2025-11-12 23:28:28,371 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9524, distance_score=0.8116, combined_score=1.3795, reliability_score=1.0000
2025-11-12 23:28:28,371 - openevolve.process_parallel - INFO - Iteration 3: Program 00176986-4d82-41a7-b11c-c70752910cb9 (parent: dc9bbfb0-2163-4b65-829f-585943ba5fd3) completed in 17.92s
2025-11-12 23:28:28,371 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9750, distance_score=0.8726, combined_score=1.4239, reliability_score=1.0000
2025-11-12 23:28:44,832 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:28:44,832 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:28:44,870 - openevolve.evaluator - INFO - Evaluated program 4872d583-39be-4e7a-8d81-3a329a770332 in 0.04s: runs_successfully=1.0000, value_score=0.9670, distance_score=0.8578, combined_score=1.4113, reliability_score=1.0000
2025-11-12 23:28:44,871 - openevolve.evaluator - INFO - Evaluated program 622f8f2f-b98e-401e-89e3-ef7828bcd53b in 0.04s: runs_successfully=1.0000, value_score=0.9457, distance_score=0.6243, combined_score=1.0322, reliability_score=1.0000
2025-11-12 23:28:44,872 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:28:44,875 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:28:44,876 - openevolve.process_parallel - INFO - Iteration 5: Program 622f8f2f-b98e-401e-89e3-ef7828bcd53b (parent: dc9bbfb0-2163-4b65-829f-585943ba5fd3) completed in 16.51s
2025-11-12 23:28:44,876 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9457, distance_score=0.6243, combined_score=1.0322, reliability_score=1.0000
2025-11-12 23:28:44,876 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 5
2025-11-12 23:28:44,876 - openevolve.database - INFO - Island Status:
2025-11-12 23:28:44,876 - openevolve.database - INFO -    Island 0: 5 programs, best=1.4320, avg=1.1118, diversity=3.40, gen=3 (best: 0cc1e0fe-1e97-4bbd-abf9-01bf6ca9cadc)
2025-11-12 23:28:44,876 - openevolve.database - INFO -  * Island 1: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=1
2025-11-12 23:28:44,877 - openevolve.database - INFO -    Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=0
2025-11-12 23:28:44,879 - openevolve.database - INFO - Saved database with 5 programs to openevolve_output/checkpoints/checkpoint_5
2025-11-12 23:28:44,879 - openevolve.controller - INFO - Saved best program at checkpoint 5 with metrics: runs_successfully=1.0000, value_score=0.9774, distance_score=0.8866, combined_score=1.4320, reliability_score=1.0000
2025-11-12 23:28:44,880 - openevolve.controller - INFO - Saved checkpoint at iteration 5 to openevolve_output/checkpoints/checkpoint_5
2025-11-12 23:28:44,880 - openevolve.process_parallel - INFO - Iteration 6: Program 4872d583-39be-4e7a-8d81-3a329a770332 (parent: dc9bbfb0-2163-4b65-829f-585943ba5fd3) completed in 16.51s
2025-11-12 23:28:44,880 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9670, distance_score=0.8578, combined_score=1.4113, reliability_score=1.0000
2025-11-12 23:28:48,141 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:28:48,147 - openevolve.evaluator - INFO - Evaluated program 4e932d41-1bd0-4959-8894-c438efbcbe63 in 0.00s: runs_successfully=1.0000, value_score=0.9528, distance_score=0.8008, combined_score=1.2488
2025-11-12 23:28:48,149 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:28:48,151 - openevolve.process_parallel - INFO - Iteration 4: Program 4e932d41-1bd0-4959-8894-c438efbcbe63 (parent: dc9bbfb0-2163-4b65-829f-585943ba5fd3) completed in 19.82s
2025-11-12 23:28:48,151 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9528, distance_score=0.8008, combined_score=1.2488
2025-11-12 23:29:13,113 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:29:13,199 - openevolve.evaluator - INFO - Evaluated program 33874a59-2960-4bd0-8f78-eaea5a218125 in 0.08s: runs_successfully=1.0000, value_score=0.6398, distance_score=0.2090, combined_score=0.4078, reliability_score=1.0000
2025-11-12 23:29:13,201 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:29:13,206 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 9, 'diversity': 9}
2025-11-12 23:29:13,207 - openevolve.process_parallel - INFO - Iteration 7: Program 33874a59-2960-4bd0-8f78-eaea5a218125 (parent: 0cc1e0fe-1e97-4bbd-abf9-01bf6ca9cadc) completed in 28.33s
2025-11-12 23:29:13,207 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.6398, distance_score=0.2090, combined_score=0.4078, reliability_score=1.0000
2025-11-12 23:29:22,512 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:29:22,550 - openevolve.evaluator - INFO - Evaluated program ff70b29f-2cb8-4d25-98d1-8414544dfbaf in 0.04s: runs_successfully=1.0000, value_score=0.9623, distance_score=0.5179, combined_score=1.0038, reliability_score=1.0000
2025-11-12 23:29:22,553 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:29:22,556 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 2, 'diversity': 0}
2025-11-12 23:29:22,556 - openevolve.process_parallel - INFO - Iteration 8: Program ff70b29f-2cb8-4d25-98d1-8414544dfbaf (parent: dc9bbfb0-2163-4b65-829f-585943ba5fd3) completed in 37.68s
2025-11-12 23:29:22,556 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9623, distance_score=0.5179, combined_score=1.0038, reliability_score=1.0000
2025-11-12 23:29:32,651 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:29:32,657 - openevolve.evaluator - INFO - Evaluated program df7f71d6-cbef-42b7-820c-c7f0509a31c9 in 0.00s: runs_successfully=1.0000, value_score=0.9456, distance_score=0.7820, combined_score=1.2322
2025-11-12 23:29:32,659 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:29:32,666 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 2, 'diversity': 0} (fitness: 1.004 -> 1.232)
2025-11-12 23:29:32,666 - openevolve.process_parallel - INFO - Iteration 9: Program df7f71d6-cbef-42b7-820c-c7f0509a31c9 (parent: 00176986-4d82-41a7-b11c-c70752910cb9) completed in 44.51s
2025-11-12 23:29:32,666 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9456, distance_score=0.7820, combined_score=1.2322
2025-11-12 23:29:48,991 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:29:48,997 - openevolve.evaluator - INFO - Evaluated program a226f30e-e74b-41e5-ad6e-9743ac1ae60c in 0.00s: runs_successfully=1.0000, value_score=0.9752, distance_score=0.8327, combined_score=1.2855
2025-11-12 23:29:48,998 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:29:49,007 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 6, 'diversity': 5}
2025-11-12 23:29:49,007 - openevolve.process_parallel - INFO - Iteration 10: Program a226f30e-e74b-41e5-ad6e-9743ac1ae60c (parent: 622f8f2f-b98e-401e-89e3-ef7828bcd53b) completed in 35.80s
2025-11-12 23:29:49,007 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9752, distance_score=0.8327, combined_score=1.2855
2025-11-12 23:29:49,007 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 10
2025-11-12 23:29:49,007 - openevolve.database - INFO - Island Status:
2025-11-12 23:29:49,007 - openevolve.database - INFO -  * Island 0: 10 programs, best=1.4320, avg=1.1145, diversity=84.83, gen=4 (best: 0cc1e0fe-1e97-4bbd-abf9-01bf6ca9cadc)
2025-11-12 23:29:49,007 - openevolve.database - INFO -    Island 1: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=3
2025-11-12 23:29:49,007 - openevolve.database - INFO -    Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=3
2025-11-12 23:29:49,010 - openevolve.database - INFO - Saved database with 11 programs to openevolve_output/checkpoints/checkpoint_10
2025-11-12 23:29:49,010 - openevolve.controller - INFO - Saved best program at checkpoint 10 with metrics: runs_successfully=1.0000, value_score=0.9774, distance_score=0.8866, combined_score=1.4320, reliability_score=1.0000
2025-11-12 23:29:49,010 - openevolve.controller - INFO - Saved checkpoint at iteration 10 to openevolve_output/checkpoints/checkpoint_10
2025-11-12 23:30:13,614 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:30:13,620 - openevolve.evaluator - INFO - Evaluated program 2c2cdba2-ae43-4aa5-9076-84904666667f in 0.00s: runs_successfully=1.0000, value_score=0.9426, distance_score=0.8408, combined_score=1.2626
2025-11-12 23:30:13,621 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:30:13,623 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 2, 'diversity': 0} (fitness: 1.232 -> 1.263)
2025-11-12 23:30:13,623 - openevolve.process_parallel - INFO - Iteration 12: Program 2c2cdba2-ae43-4aa5-9076-84904666667f (parent: dc9bbfb0-2163-4b65-829f-585943ba5fd3) completed in 40.96s
2025-11-12 23:30:13,623 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9426, distance_score=0.8408, combined_score=1.2626
2025-11-12 23:30:24,236 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:30:24,273 - openevolve.evaluator - INFO - Evaluated program 8c2313f1-46a0-4a6f-8e73-523859418daf in 0.04s: runs_successfully=1.0000, value_score=0.9593, distance_score=0.8250, combined_score=1.3907, reliability_score=1.0000
2025-11-12 23:30:24,275 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:30:24,279 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 2, 'diversity': 0} (fitness: 1.263 -> 1.391)
2025-11-12 23:30:24,279 - openevolve.process_parallel - INFO - Iteration 11: Program 8c2313f1-46a0-4a6f-8e73-523859418daf (parent: 4872d583-39be-4e7a-8d81-3a329a770332) completed in 61.72s
2025-11-12 23:30:24,279 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9593, distance_score=0.8250, combined_score=1.3907, reliability_score=1.0000
2025-11-12 23:31:02,178 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:31:02,183 - openevolve.evaluator - INFO - Evaluated program ed5fc0a7-5dd3-4997-882d-1a4a5efc54f2 in 0.00s: runs_successfully=1.0000, value_score=0.9549, distance_score=0.8337, combined_score=1.2690
2025-11-12 23:31:02,185 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:31:02,193 - openevolve.process_parallel - INFO - Iteration 13: Program ed5fc0a7-5dd3-4997-882d-1a4a5efc54f2 (parent: 622f8f2f-b98e-401e-89e3-ef7828bcd53b) completed in 73.19s
2025-11-12 23:31:02,193 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9549, distance_score=0.8337, combined_score=1.2690
2025-11-12 23:31:19,836 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:31:19,842 - openevolve.evaluator - INFO - Evaluated program 238b5b40-7d4f-4d9d-9b87-5a2d83bcd78a in 0.00s: runs_successfully=1.0000, value_score=0.9779, distance_score=0.8538, combined_score=1.2996
2025-11-12 23:31:19,843 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:31:19,849 - openevolve.process_parallel - INFO - Iteration 14: Program 238b5b40-7d4f-4d9d-9b87-5a2d83bcd78a (parent: ff70b29f-2cb8-4d25-98d1-8414544dfbaf) completed in 66.22s
2025-11-12 23:31:19,849 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9779, distance_score=0.8538, combined_score=1.2996
2025-11-12 23:31:31,560 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:31:31,567 - openevolve.evaluator - INFO - Evaluated program 1426ac16-961b-422e-8e42-162bfb61b8f2 in 0.01s: runs_successfully=1.0000, value_score=0.9490, distance_score=0.7860, combined_score=1.2373
2025-11-12 23:31:31,568 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:31:31,574 - openevolve.process_parallel - INFO - Iteration 15: Program 1426ac16-961b-422e-8e42-162bfb61b8f2 (parent: dc9bbfb0-2163-4b65-829f-585943ba5fd3) completed in 67.29s
2025-11-12 23:31:31,574 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9490, distance_score=0.7860, combined_score=1.2373
2025-11-12 23:31:31,574 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 15
2025-11-12 23:31:31,574 - openevolve.database - INFO - Island Status:
2025-11-12 23:31:31,574 - openevolve.database - INFO -    Island 0: 13 programs, best=1.4320, avg=1.1622, diversity=42.42, gen=6 (best: 0cc1e0fe-1e97-4bbd-abf9-01bf6ca9cadc)
2025-11-12 23:31:31,575 - openevolve.database - INFO -  * Island 1: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=6
2025-11-12 23:31:31,575 - openevolve.database - INFO -    Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=3
2025-11-12 23:31:31,578 - openevolve.database - INFO - Saved database with 16 programs to openevolve_output/checkpoints/checkpoint_15
2025-11-12 23:31:31,578 - openevolve.controller - INFO - Saved best program at checkpoint 15 with metrics: runs_successfully=1.0000, value_score=0.9774, distance_score=0.8866, combined_score=1.4320, reliability_score=1.0000
2025-11-12 23:31:31,578 - openevolve.controller - INFO - Saved checkpoint at iteration 15 to openevolve_output/checkpoints/checkpoint_15
2025-11-12 23:31:42,495 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:31:42,533 - openevolve.evaluator - INFO - Evaluated program 664e9604-c959-490d-8e8f-5b4673ad95f5 in 0.04s: runs_successfully=1.0000, value_score=0.9673, distance_score=0.8586, combined_score=1.4119, reliability_score=1.0000
2025-11-12 23:31:42,535 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:31:42,536 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 6, 'diversity': 5} (fitness: 1.285 -> 1.412)
2025-11-12 23:31:42,536 - openevolve.process_parallel - INFO - Iteration 16: Program 664e9604-c959-490d-8e8f-5b4673ad95f5 (parent: 4e932d41-1bd0-4959-8894-c438efbcbe63) completed in 40.35s
2025-11-12 23:31:42,536 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9673, distance_score=0.8586, combined_score=1.4119, reliability_score=1.0000
2025-11-12 23:31:55,654 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:31:55,692 - openevolve.evaluator - INFO - Evaluated program d200a8c0-f616-4a9d-b9ad-bd2c86ea4bb0 in 0.04s: runs_successfully=1.0000, value_score=0.9662, distance_score=0.8502, combined_score=1.4072, reliability_score=1.0000
2025-11-12 23:31:55,693 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:31:55,700 - openevolve.process_parallel - INFO - Iteration 17: Program d200a8c0-f616-4a9d-b9ad-bd2c86ea4bb0 (parent: dc9bbfb0-2163-4b65-829f-585943ba5fd3) completed in 35.85s
2025-11-12 23:31:55,700 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9662, distance_score=0.8502, combined_score=1.4072, reliability_score=1.0000
2025-11-12 23:32:05,115 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:32:05,601 - openevolve.evaluator - INFO - Evaluated program 4948e14e-f04b-4c1e-b1e3-9c7c78265a20 in 0.48s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:32:05,602 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:32:05,611 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 0, 'diversity': 4}
2025-11-12 23:32:05,611 - openevolve.database - INFO - New best program 4948e14e-f04b-4c1e-b1e3-9c7c78265a20 replaces 0cc1e0fe-1e97-4bbd-abf9-01bf6ca9cadc (combined_score: 1.4320 â†’ 1.4995, +0.0675)
2025-11-12 23:32:05,611 - openevolve.process_parallel - INFO - Iteration 18: Program 4948e14e-f04b-4c1e-b1e3-9c7c78265a20 (parent: a226f30e-e74b-41e5-ad6e-9743ac1ae60c) completed in 34.03s
2025-11-12 23:32:05,611 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:32:05,611 - openevolve.process_parallel - INFO - ðŸŒŸ New best solution found at iteration 18: 4948e14e-f04b-4c1e-b1e3-9c7c78265a20
2025-11-12 23:32:24,539 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:32:24,542 - openevolve.evaluator - INFO - Evaluated program 896acffb-b070-4566-ad24-ea6bca75e8d0 in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error=Missing run_search function
2025-11-12 23:32:24,544 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:32:24,549 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 1, 'diversity': 4}
2025-11-12 23:32:24,549 - openevolve.process_parallel - INFO - Iteration 20: Program 896acffb-b070-4566-ad24-ea6bca75e8d0 (parent: 622f8f2f-b98e-401e-89e3-ef7828bcd53b) completed in 28.85s
2025-11-12 23:32:24,549 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=Missing run_search function
2025-11-12 23:32:24,549 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 20
2025-11-12 23:32:24,549 - openevolve.database - INFO - Island Status:
2025-11-12 23:32:24,549 - openevolve.database - INFO -  * Island 0: 16 programs, best=1.4995, avg=1.1339, diversity=42.42, gen=7 (best: 4948e14e-f04b-4c1e-b1e3-9c7c78265a20)
2025-11-12 23:32:24,549 - openevolve.database - INFO -    Island 1: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=6
2025-11-12 23:32:24,549 - openevolve.database - INFO -    Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=6
2025-11-12 23:32:24,554 - openevolve.database - INFO - Saved database with 20 programs to openevolve_output/checkpoints/checkpoint_20
2025-11-12 23:32:24,555 - openevolve.controller - INFO - Saved best program at checkpoint 20 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:32:24,555 - openevolve.controller - INFO - Saved checkpoint at iteration 20 to openevolve_output/checkpoints/checkpoint_20
2025-11-12 23:33:04,530 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:33:04,534 - openevolve.evaluator - INFO - Evaluated program dee9c057-3fb6-4c55-9cfd-c382ce0d96ad in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error='return' outside function (tmpi8aiyk63.py, line 90)
2025-11-12 23:33:04,536 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:33:04,542 - openevolve.process_parallel - INFO - Iteration 19: Program dee9c057-3fb6-4c55-9cfd-c382ce0d96ad (parent: 33874a59-2960-4bd0-8f78-eaea5a218125) completed in 82.00s
2025-11-12 23:33:04,542 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error='return' outside function (tmpi8aiyk63.py, line 90)
2025-11-12 23:33:11,630 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:33:11,638 - openevolve.evaluator - INFO - Evaluated program 04d4c052-416a-43d2-8b85-c368415cde4f in 0.01s: runs_successfully=1.0000, value_score=0.9601, distance_score=0.7937, combined_score=1.2509
2025-11-12 23:33:11,640 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:33:11,643 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 0, 'diversity': 0}
2025-11-12 23:33:11,644 - openevolve.process_parallel - INFO - Iteration 21: Program 04d4c052-416a-43d2-8b85-c368415cde4f (parent: 00176986-4d82-41a7-b11c-c70752910cb9) completed in 66.04s
2025-11-12 23:33:11,644 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9601, distance_score=0.7937, combined_score=1.2509
2025-11-12 23:33:39,451 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:33:39,456 - openevolve.evaluator - INFO - Evaluated program 73dacbc1-a62d-4201-a53d-0f172d4eb41d in 0.00s: runs_successfully=1.0000, value_score=0.9498, distance_score=0.8241, combined_score=1.2593
2025-11-12 23:33:39,458 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:33:39,466 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 1, 'diversity': 0}
2025-11-12 23:33:39,466 - openevolve.process_parallel - INFO - Iteration 23: Program 73dacbc1-a62d-4201-a53d-0f172d4eb41d (parent: 4872d583-39be-4e7a-8d81-3a329a770332) completed in 34.92s
2025-11-12 23:33:39,466 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9498, distance_score=0.8241, combined_score=1.2593
2025-11-12 23:34:24,644 - openevolve.llm.openai - WARNING - Timeout on attempt 1/4. Retrying...
2025-11-12 23:34:24,645 - openai._base_client - INFO - Retrying request to /chat/completions in 0.399030 seconds
2025-11-12 23:34:32,961 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:34:32,964 - openevolve.evaluator - INFO - Evaluated program 62597fa8-09a9-461d-aea0-0cb225073731 in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error=invalid syntax (tmppo9qo6a_.py, line 6)
2025-11-12 23:34:32,966 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:34:32,973 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 2, 'diversity': 1}
2025-11-12 23:34:32,973 - openevolve.database - INFO - Island 0 MAP-Elites coverage reached 10.0% (10/100 cells)
2025-11-12 23:34:32,973 - openevolve.process_parallel - INFO - Iteration 24: Program 62597fa8-09a9-461d-aea0-0cb225073731 (parent: 00176986-4d82-41a7-b11c-c70752910cb9) completed in 81.32s
2025-11-12 23:34:32,973 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=invalid syntax (tmppo9qo6a_.py, line 6)
2025-11-12 23:34:34,259 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:34:34,259 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:34:34,263 - openevolve.evaluator - INFO - Evaluated program 3a4f34a0-f1fc-4243-8559-4a6488795f46 in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error=invalid syntax (tmpj08oqoz_.py, line 1)
2025-11-12 23:34:34,264 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:34:34,270 - openevolve.process_parallel - INFO - Iteration 22: Program 3a4f34a0-f1fc-4243-8559-4a6488795f46 (parent: 622f8f2f-b98e-401e-89e3-ef7828bcd53b) completed in 129.72s
2025-11-12 23:34:34,270 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=invalid syntax (tmpj08oqoz_.py, line 1)
2025-11-12 23:34:44,658 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:34:44,829 - openevolve.evaluator - INFO - Evaluated program 022ef4ef-81ee-4af1-857d-c7e3bfbd7edd in 0.17s: runs_successfully=0.0000, combined_score=0.0000, error='numpy.float64' object does not support item assignment
2025-11-12 23:34:44,831 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:34:44,841 - openevolve.process_parallel - INFO - Iteration 25: Program 022ef4ef-81ee-4af1-857d-c7e3bfbd7edd (parent: 4948e14e-f04b-4c1e-b1e3-9c7c78265a20) completed in 65.37s
2025-11-12 23:34:44,841 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error='numpy.float64' object does not support item assignment
2025-11-12 23:34:44,841 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 25
2025-11-12 23:34:44,841 - openevolve.database - INFO - Island Status:
2025-11-12 23:34:44,841 - openevolve.database - INFO -    Island 0: 22 programs, best=1.4995, avg=0.9388, diversity=57.70, gen=9 (best: 4948e14e-f04b-4c1e-b1e3-9c7c78265a20)
2025-11-12 23:34:44,841 - openevolve.database - INFO -    Island 1: 1 programs, best=1.4995, avg=1.4995, diversity=0.00, gen=9
2025-11-12 23:34:44,841 - openevolve.database - INFO -  * Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=7
2025-11-12 23:34:44,847 - openevolve.database - INFO - Saved database with 27 programs to openevolve_output/checkpoints/checkpoint_25
2025-11-12 23:34:44,847 - openevolve.controller - INFO - Saved best program at checkpoint 25 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:34:44,847 - openevolve.controller - INFO - Saved checkpoint at iteration 25 to openevolve_output/checkpoints/checkpoint_25
2025-11-12 23:35:02,093 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:35:02,284 - openevolve.evaluator - INFO - Evaluated program 8c4b4849-e346-4b98-a908-afe4b07972ab in 0.19s: runs_successfully=0.0000, combined_score=0.0000, error=unsupported operand type(s) for -: 'tuple' and 'tuple'
2025-11-12 23:35:02,285 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:35:02,292 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 4, 'diversity': 1}
2025-11-12 23:35:02,292 - openevolve.process_parallel - INFO - Iteration 27: Program 8c4b4849-e346-4b98-a908-afe4b07972ab (parent: 33874a59-2960-4bd0-8f78-eaea5a218125) completed in 28.02s
2025-11-12 23:35:02,292 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=unsupported operand type(s) for -: 'tuple' and 'tuple'
2025-11-12 23:35:04,026 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:35:04,544 - openevolve.evaluator - INFO - Evaluated program 6970cd62-d9ad-4743-9a2e-d00ea5cdb3d5 in 0.52s: runs_successfully=1.0000, value_score=0.9804, distance_score=0.5561, combined_score=1.0284, reliability_score=1.0000
2025-11-12 23:35:04,545 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:35:04,547 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 4, 'diversity': 1} (fitness: 0.000 -> 1.028)
2025-11-12 23:35:04,547 - openevolve.process_parallel - INFO - Iteration 26: Program 6970cd62-d9ad-4743-9a2e-d00ea5cdb3d5 (parent: 33874a59-2960-4bd0-8f78-eaea5a218125) completed in 31.58s
2025-11-12 23:35:04,547 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9804, distance_score=0.5561, combined_score=1.0284, reliability_score=1.0000
2025-11-12 23:35:21,639 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:35:23,173 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:35:23,401 - openevolve.evaluator - INFO - Evaluated program 89b833b7-8470-4323-92a3-2eb7ffc306f8 in 1.76s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:35:23,403 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:35:23,409 - openevolve.database - INFO - New MAP-Elites cell occupied in island 1: {'complexity': 2, 'diversity': 0}
2025-11-12 23:35:23,410 - openevolve.database - INFO - New best program 89b833b7-8470-4323-92a3-2eb7ffc306f8 replaces 4948e14e-f04b-4c1e-b1e3-9c7c78265a20 (combined_score: 1.4995 â†’ 1.4995, +0.0000)
2025-11-12 23:35:23,410 - openevolve.process_parallel - INFO - Iteration 29: Program 89b833b7-8470-4323-92a3-2eb7ffc306f8 (parent: 797fe526-2433-40d1-ba7c-05f3f9173973) completed in 21.12s
2025-11-12 23:35:23,410 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:35:23,410 - openevolve.process_parallel - INFO - ðŸŒŸ New best solution found at iteration 29: 89b833b7-8470-4323-92a3-2eb7ffc306f8
2025-11-12 23:35:24,861 - openevolve.evaluator - INFO - Evaluated program 7446cd28-1859-42ee-94e5-f107b978f765 in 1.69s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:35:24,863 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:35:24,866 - openevolve.process_parallel - INFO - Iteration 30: Program 7446cd28-1859-42ee-94e5-f107b978f765 (parent: 797fe526-2433-40d1-ba7c-05f3f9173973) completed in 20.32s
2025-11-12 23:35:24,866 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:35:24,866 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 30
2025-11-12 23:35:24,866 - openevolve.database - INFO - Island Status:
2025-11-12 23:35:24,866 - openevolve.database - INFO -  * Island 0: 23 programs, best=1.4995, avg=0.9427, diversity=57.70, gen=11 (best: 4948e14e-f04b-4c1e-b1e3-9c7c78265a20)
2025-11-12 23:35:24,866 - openevolve.database - INFO -    Island 1: 3 programs, best=1.4995, avg=1.4995, diversity=74.47, gen=9 (best: 89b833b7-8470-4323-92a3-2eb7ffc306f8)
2025-11-12 23:35:24,866 - openevolve.database - INFO -    Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=9
2025-11-12 23:35:24,872 - openevolve.database - INFO - Saved database with 31 programs to openevolve_output/checkpoints/checkpoint_30
2025-11-12 23:35:24,873 - openevolve.controller - INFO - Saved best program at checkpoint 30 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:35:24,873 - openevolve.controller - INFO - Saved checkpoint at iteration 30 to openevolve_output/checkpoints/checkpoint_30
2025-11-12 23:35:42,797 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:35:43,157 - openevolve.evaluator - INFO - Evaluated program 0859b858-94a5-4686-9890-1e6b8faea440 in 0.36s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:35:43,159 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:35:43,163 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 9, 'diversity': 9} (fitness: 0.408 -> 1.500)
2025-11-12 23:35:43,163 - openevolve.process_parallel - INFO - Iteration 28: Program 0859b858-94a5-4686-9890-1e6b8faea440 (parent: 4872d583-39be-4e7a-8d81-3a329a770332) completed in 58.33s
2025-11-12 23:35:43,163 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:35:52,397 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:35:54,086 - openevolve.evaluator - INFO - Evaluated program b39535ca-ef5b-4ba7-addb-c0930ed06fe4 in 1.69s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:35:54,089 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:35:54,089 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 2, 'diversity': 0} (fitness: 1.391 -> 1.500)
2025-11-12 23:35:54,089 - openevolve.database - INFO - New best program b39535ca-ef5b-4ba7-addb-c0930ed06fe4 replaces 89b833b7-8470-4323-92a3-2eb7ffc306f8 (combined_score: 1.4995 â†’ 1.4995, +0.0000)
2025-11-12 23:35:54,090 - openevolve.process_parallel - INFO - Iteration 31: Program b39535ca-ef5b-4ba7-addb-c0930ed06fe4 (parent: 88aba674-97c5-46fa-a95a-384092721017) completed in 30.68s
2025-11-12 23:35:54,090 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:35:54,090 - openevolve.process_parallel - INFO - ðŸŒŸ New best solution found at iteration 31: b39535ca-ef5b-4ba7-addb-c0930ed06fe4
2025-11-12 23:36:15,039 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:36:15,367 - openevolve.evaluator - INFO - Evaluated program ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f in 0.33s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:36:15,369 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:36:15,370 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 2, 'diversity': 0} (fitness: 1.500 -> 1.500)
2025-11-12 23:36:15,371 - openevolve.database - INFO - New best program ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f replaces b39535ca-ef5b-4ba7-addb-c0930ed06fe4 (combined_score: 1.4995 â†’ 1.4995, +0.0000)
2025-11-12 23:36:15,371 - openevolve.process_parallel - INFO - Iteration 32: Program ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f (parent: 73dacbc1-a62d-4201-a53d-0f172d4eb41d) completed in 50.50s
2025-11-12 23:36:15,371 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:36:15,371 - openevolve.process_parallel - INFO - ðŸŒŸ New best solution found at iteration 32: ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f
2025-11-12 23:36:22,831 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:36:23,172 - openevolve.evaluator - INFO - Evaluated program 98947053-0871-42c2-adec-4def7703ceb1 in 0.34s: runs_successfully=1.0000, value_score=0.9804, distance_score=0.5561, combined_score=1.0284, reliability_score=1.0000
2025-11-12 23:36:23,173 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:36:23,176 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 4, 'diversity': 2}
2025-11-12 23:36:23,176 - openevolve.process_parallel - INFO - Iteration 33: Program 98947053-0871-42c2-adec-4def7703ceb1 (parent: dc9bbfb0-2163-4b65-829f-585943ba5fd3) completed in 40.01s
2025-11-12 23:36:23,176 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9804, distance_score=0.5561, combined_score=1.0284, reliability_score=1.0000
2025-11-12 23:36:46,388 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:36:47,326 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:36:47,794 - openevolve.evaluator - INFO - Evaluated program 7c4ad811-aa13-4b57-aeef-07fcc3ee56d8 in 0.47s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:36:47,797 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:36:47,806 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 4, 'diversity': 2} (fitness: 1.028 -> 1.500)
2025-11-12 23:36:47,806 - openevolve.process_parallel - INFO - Iteration 34: Program 7c4ad811-aa13-4b57-aeef-07fcc3ee56d8 (parent: 4e932d41-1bd0-4959-8894-c438efbcbe63) completed in 53.71s
2025-11-12 23:36:47,806 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:36:49,736 - openevolve.evaluator - INFO - Evaluated program 6330d97a-726b-4dab-8293-cd09ac328868 in 3.35s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:36:49,738 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:36:49,742 - openevolve.process_parallel - INFO - Iteration 35: Program 6330d97a-726b-4dab-8293-cd09ac328868 (parent: dc9bbfb0-2163-4b65-829f-585943ba5fd3) completed in 34.37s
2025-11-12 23:36:49,742 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:36:49,743 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 35
2025-11-12 23:36:49,743 - openevolve.database - INFO - Island Status:
2025-11-12 23:36:49,743 - openevolve.database - INFO -    Island 0: 25 programs, best=1.4995, avg=1.0352, diversity=517.40, gen=12 (best: ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f)
2025-11-12 23:36:49,743 - openevolve.database - INFO -    Island 1: 3 programs, best=1.4995, avg=1.4995, diversity=74.47, gen=12 (best: 89b833b7-8470-4323-92a3-2eb7ffc306f8)
2025-11-12 23:36:49,743 - openevolve.database - INFO -  * Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=11
2025-11-12 23:36:49,754 - openevolve.database - INFO - Saved database with 37 programs to openevolve_output/checkpoints/checkpoint_35
2025-11-12 23:36:49,754 - openevolve.controller - INFO - Saved best program at checkpoint 35 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:36:49,754 - openevolve.controller - INFO - Saved checkpoint at iteration 35 to openevolve_output/checkpoints/checkpoint_35
2025-11-12 23:37:06,611 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:37:08,258 - openevolve.evaluator - INFO - Evaluated program 2cf7c89e-7adc-4bb1-b085-e67acad9bb00 in 1.65s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:37:08,260 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:37:08,265 - openevolve.process_parallel - INFO - Iteration 36: Program 2cf7c89e-7adc-4bb1-b085-e67acad9bb00 (parent: 89b833b7-8470-4323-92a3-2eb7ffc306f8) completed in 45.09s
2025-11-12 23:37:08,265 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:37:11,281 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:37:11,423 - openevolve.evaluator - INFO - Evaluated program 8574d0ac-9d39-44a7-ad0f-a9ee70f8b170 in 0.14s: runs_successfully=0.0000, combined_score=0.0000, error=differential_evolution() got an unexpected keyword argument 'stepsize'
2025-11-12 23:37:11,426 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:37:11,434 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 3, 'diversity': 0}
2025-11-12 23:37:11,435 - openevolve.process_parallel - INFO - Iteration 37: Program 8574d0ac-9d39-44a7-ad0f-a9ee70f8b170 (parent: 04d4c052-416a-43d2-8b85-c368415cde4f) completed in 23.63s
2025-11-12 23:37:11,435 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=differential_evolution() got an unexpected keyword argument 'stepsize'
2025-11-12 23:37:23,210 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:37:26,467 - openevolve.evaluator - INFO - Evaluated program 2fa04697-34c4-4568-977e-e441b181285c in 3.26s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:37:26,469 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:37:26,478 - openevolve.database - INFO - New MAP-Elites cell occupied in island 1: {'complexity': 4, 'diversity': 1}
2025-11-12 23:37:26,479 - openevolve.process_parallel - INFO - Iteration 38: Program 2fa04697-34c4-4568-977e-e441b181285c (parent: 797fe526-2433-40d1-ba7c-05f3f9173973) completed in 36.73s
2025-11-12 23:37:26,479 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:37:58,265 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:37:58,595 - openevolve.evaluator - INFO - Evaluated program 7c476a23-ad51-4848-8c4f-3bb6bd0a0b7e in 0.33s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:37:58,596 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:37:58,602 - openevolve.process_parallel - INFO - Iteration 39: Program 7c476a23-ad51-4848-8c4f-3bb6bd0a0b7e (parent: d200a8c0-f616-4a9d-b9ad-bd2c86ea4bb0) completed in 50.33s
2025-11-12 23:37:58,602 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:38:29,785 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:38:30,138 - openevolve.evaluator - INFO - Evaluated program ba2ac94c-68f5-49a7-a1ee-3fb66442a83f in 0.35s: runs_successfully=1.0000, value_score=0.9900, distance_score=0.7146, combined_score=1.3640, reliability_score=1.0000
2025-11-12 23:38:30,140 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:38:30,144 - openevolve.process_parallel - INFO - Iteration 40: Program ba2ac94c-68f5-49a7-a1ee-3fb66442a83f (parent: 1426ac16-961b-422e-8e42-162bfb61b8f2) completed in 78.71s
2025-11-12 23:38:30,144 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9900, distance_score=0.7146, combined_score=1.3640, reliability_score=1.0000
2025-11-12 23:38:30,144 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 40
2025-11-12 23:38:30,145 - openevolve.database - INFO - Island Status:
2025-11-12 23:38:30,145 - openevolve.database - INFO -    Island 0: 28 programs, best=1.4995, avg=1.0266, diversity=517.40, gen=15 (best: ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f)
2025-11-12 23:38:30,145 - openevolve.database - INFO -  * Island 1: 5 programs, best=1.4995, avg=1.4995, diversity=119.28, gen=13 (best: 2fa04697-34c4-4568-977e-e441b181285c)
2025-11-12 23:38:30,145 - openevolve.database - INFO -    Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=12
2025-11-12 23:38:30,157 - openevolve.database - INFO - Saved database with 42 programs to openevolve_output/checkpoints/checkpoint_40
2025-11-12 23:38:30,157 - openevolve.controller - INFO - Saved best program at checkpoint 40 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:38:30,157 - openevolve.controller - INFO - Saved checkpoint at iteration 40 to openevolve_output/checkpoints/checkpoint_40
2025-11-12 23:38:38,217 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:38:41,378 - openevolve.evaluator - INFO - Evaluated program f7918a9e-8920-4ce0-9fb6-6a79189bde5b in 3.16s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:38:41,380 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:38:41,389 - openevolve.process_parallel - INFO - Iteration 41: Program f7918a9e-8920-4ce0-9fb6-6a79189bde5b (parent: 622f8f2f-b98e-401e-89e3-ef7828bcd53b) completed in 74.91s
2025-11-12 23:38:41,389 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:39:00,605 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:39:02,209 - openevolve.evaluator - INFO - Evaluated program d238e871-ce57-461d-a2aa-d7df79dfdeb4 in 1.60s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:39:02,211 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:39:02,215 - openevolve.database - INFO - Island 1 MAP-Elites cell improved: {'complexity': 2, 'diversity': 0} (fitness: 1.500 -> 1.500)
2025-11-12 23:39:02,215 - openevolve.process_parallel - INFO - Iteration 42: Program d238e871-ce57-461d-a2aa-d7df79dfdeb4 (parent: 2cf7c89e-7adc-4bb1-b085-e67acad9bb00) completed in 63.61s
2025-11-12 23:39:02,215 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:39:19,360 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:39:19,364 - openevolve.evaluator - INFO - Evaluated program 34da3bcb-e203-47a7-8c90-2920d0802608 in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error='(' was never closed (tmp2mgvzzjx.py, line 59)
2025-11-12 23:39:19,365 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:39:19,370 - openevolve.process_parallel - INFO - Iteration 43: Program 34da3bcb-e203-47a7-8c90-2920d0802608 (parent: 6330d97a-726b-4dab-8293-cd09ac328868) completed in 49.22s
2025-11-12 23:39:19,370 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error='(' was never closed (tmp2mgvzzjx.py, line 59)
2025-11-12 23:39:23,935 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:39:23,938 - openevolve.evaluator - INFO - Evaluated program 6437e22d-6f43-45fa-ab37-248b663e566d in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error=invalid syntax (tmpthuxttmr.py, line 12)
2025-11-12 23:39:23,940 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:39:23,947 - openevolve.database - INFO - New MAP-Elites cell occupied in island 1: {'complexity': 2, 'diversity': 1}
2025-11-12 23:39:23,947 - openevolve.process_parallel - INFO - Iteration 44: Program 6437e22d-6f43-45fa-ab37-248b663e566d (parent: 7446cd28-1859-42ee-94e5-f107b978f765) completed in 42.56s
2025-11-12 23:39:23,947 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=invalid syntax (tmpthuxttmr.py, line 12)
2025-11-12 23:39:46,943 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:39:50,223 - openevolve.evaluator - INFO - Evaluated program b7c17162-838e-43be-bf12-15ea6a8061a0 in 3.28s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:39:50,224 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:39:50,229 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 3, 'diversity': 0} (fitness: 0.000 -> 1.500)
2025-11-12 23:39:50,229 - openevolve.process_parallel - INFO - Iteration 45: Program b7c17162-838e-43be-bf12-15ea6a8061a0 (parent: 896acffb-b070-4566-ad24-ea6bca75e8d0) completed in 48.01s
2025-11-12 23:39:50,229 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:39:50,229 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 45
2025-11-12 23:39:50,230 - openevolve.database - INFO - Island Status:
2025-11-12 23:39:50,230 - openevolve.database - INFO -    Island 0: 30 programs, best=1.4995, avg=1.0581, diversity=517.40, gen=15 (best: ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f)
2025-11-12 23:39:50,230 - openevolve.database - INFO -    Island 1: 6 programs, best=1.4995, avg=1.2496, diversity=158.40, gen=15 (best: 2fa04697-34c4-4568-977e-e441b181285c)
2025-11-12 23:39:50,230 - openevolve.database - INFO -  * Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=15
2025-11-12 23:39:50,243 - openevolve.database - INFO - Saved database with 47 programs to openevolve_output/checkpoints/checkpoint_45
2025-11-12 23:39:50,243 - openevolve.controller - INFO - Saved best program at checkpoint 45 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:39:50,243 - openevolve.controller - INFO - Saved checkpoint at iteration 45 to openevolve_output/checkpoints/checkpoint_45
2025-11-12 23:39:53,218 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:39:56,526 - openevolve.evaluator - INFO - Evaluated program ccf2300c-a72c-4a6b-bab1-b1a1976dc4cf in 3.31s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:39:56,527 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:39:56,532 - openevolve.database - INFO - New MAP-Elites cell occupied in island 1: {'complexity': 5, 'diversity': 2}
2025-11-12 23:39:56,532 - openevolve.process_parallel - INFO - Iteration 46: Program ccf2300c-a72c-4a6b-bab1-b1a1976dc4cf (parent: 2fa04697-34c4-4568-977e-e441b181285c) completed in 37.16s
2025-11-12 23:39:56,533 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:39:56,558 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:39:56,558 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6094 input tokens (6000 > 12000 - 6094). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:40:01,587 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:40:01,590 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6094 input tokens (6000 > 12000 - 6094). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:40:05,489 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:40:06,627 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:40:06,627 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6094 input tokens (6000 > 12000 - 6094). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:40:07,098 - openevolve.evaluator - INFO - Evaluated program ef9e4710-272e-4e62-b73b-dc2787ad5144 in 1.61s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:40:07,099 - openevolve.process_parallel - INFO - Iteration 47: Program ef9e4710-272e-4e62-b73b-dc2787ad5144 (parent: 2cf7c89e-7adc-4bb1-b085-e67acad9bb00) completed in 43.16s
2025-11-12 23:40:07,099 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:40:07,099 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:40:11,656 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:40:11,656 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6094 input tokens (6000 > 12000 - 6094). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:40:11,657 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6094 input tokens (6000 > 12000 - 6094). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:40:11,659 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:40:11,667 - openevolve.process_parallel - WARNING - Iteration 49 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6094 input tokens (6000 > 12000 - 6094). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:40:21,325 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:40:24,472 - openevolve.evaluator - INFO - Evaluated program 217d78b5-7d3b-4146-b2ba-d892be1049c7 in 3.15s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:40:24,474 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:40:24,477 - openevolve.database - INFO - Island 1 MAP-Elites cell improved: {'complexity': 5, 'diversity': 2} (fitness: 1.500 -> 1.500)
2025-11-12 23:40:24,477 - openevolve.process_parallel - INFO - Iteration 48: Program 217d78b5-7d3b-4146-b2ba-d892be1049c7 (parent: 2fa04697-34c4-4568-977e-e441b181285c) completed in 34.25s
2025-11-12 23:40:24,477 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:40:38,861 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:40:42,046 - openevolve.evaluator - INFO - Evaluated program 620f4e43-41dc-4f5f-84ac-f7242c9cb9f2 in 3.18s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:40:42,050 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:40:42,058 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:40:42,058 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:40:42,058 - openevolve.process_parallel - INFO - Iteration 51: Program 620f4e43-41dc-4f5f-84ac-f7242c9cb9f2 (parent: 238b5b40-7d4f-4d9d-9b87-5a2d83bcd78a) completed in 30.39s
2025-11-12 23:40:42,058 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:41:00,137 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:41:00,140 - openevolve.evaluator - INFO - Evaluated program 72e9219c-d3bb-40b6-a33f-ecdf116a06e5 in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error=invalid syntax (tmp3v_hnzo0.py, line 1)
2025-11-12 23:41:00,142 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:41:00,150 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 4, 'diversity': 0}
2025-11-12 23:41:00,150 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:41:00,150 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:41:00,150 - openevolve.process_parallel - INFO - Iteration 52: Program 72e9219c-d3bb-40b6-a33f-ecdf116a06e5 (parent: 6330d97a-726b-4dab-8293-cd09ac328868) completed in 35.67s
2025-11-12 23:41:00,150 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=invalid syntax (tmp3v_hnzo0.py, line 1)
2025-11-12 23:41:01,927 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:41:01,930 - openevolve.evaluator - INFO - Evaluated program 879f538b-90aa-4a77-85ed-72e4b768cfa5 in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error=invalid syntax (tmpmo70kg5z.py, line 1)
2025-11-12 23:41:01,931 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:41:01,933 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:41:01,933 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:41:01,933 - openevolve.process_parallel - INFO - Iteration 53: Program 879f538b-90aa-4a77-85ed-72e4b768cfa5 (parent: 4872d583-39be-4e7a-8d81-3a329a770332) completed in 19.88s
2025-11-12 23:41:01,933 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=invalid syntax (tmpmo70kg5z.py, line 1)
2025-11-12 23:41:11,260 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:41:14,423 - openevolve.evaluator - INFO - Evaluated program ed120499-138e-493e-826b-17bcfe44967b in 3.16s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:41:14,424 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:41:14,424 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:41:14,424 - openevolve.process_parallel - INFO - Iteration 50: Program ed120499-138e-493e-826b-17bcfe44967b (parent: 2fa04697-34c4-4568-977e-e441b181285c) completed in 67.32s
2025-11-12 23:41:14,424 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:41:14,424 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 50
2025-11-12 23:41:14,424 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:41:14,426 - openevolve.database - INFO - Island Status:
2025-11-12 23:41:14,426 - openevolve.database - INFO -    Island 0: 29 programs, best=1.4995, avg=1.1463, diversity=517.40, gen=18 (best: ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f)
2025-11-12 23:41:14,426 - openevolve.database - INFO -    Island 1: 9 programs, best=1.4995, avg=1.3329, diversity=277.33, gen=18 (best: 2fa04697-34c4-4568-977e-e441b181285c)
2025-11-12 23:41:14,426 - openevolve.database - INFO -  * Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=16
2025-11-12 23:41:14,437 - openevolve.database - INFO - Saved database with 50 programs to openevolve_output/checkpoints/checkpoint_50
2025-11-12 23:41:14,437 - openevolve.controller - INFO - Saved best program at checkpoint 50 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:41:14,437 - openevolve.controller - INFO - Saved checkpoint at iteration 50 to openevolve_output/checkpoints/checkpoint_50
2025-11-12 23:41:48,086 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:41:49,409 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:41:49,413 - openevolve.evaluator - INFO - Evaluated program 00681225-8b95-42fe-b281-be6797cac023 in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error=unsupported operand type(s) for -: 'tuple' and 'tuple'
2025-11-12 23:41:49,415 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:41:49,418 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 8, 'diversity': 5}
2025-11-12 23:41:49,418 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:41:49,418 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:41:49,418 - openevolve.process_parallel - INFO - Iteration 54: Program 00681225-8b95-42fe-b281-be6797cac023 (parent: 4948e14e-f04b-4c1e-b1e3-9c7c78265a20) completed in 49.27s
2025-11-12 23:41:49,418 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=unsupported operand type(s) for -: 'tuple' and 'tuple'
2025-11-12 23:41:51,407 - openevolve.evaluator - INFO - Evaluated program 6dde66c8-e7ea-4596-9688-25a2bef3f2ef in 3.32s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:41:51,408 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:41:51,413 - openevolve.database - INFO - Island 1 MAP-Elites cell improved: {'complexity': 5, 'diversity': 2} (fitness: 1.500 -> 1.500)
2025-11-12 23:41:51,413 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:41:51,413 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:41:51,413 - openevolve.process_parallel - INFO - Iteration 55: Program 6dde66c8-e7ea-4596-9688-25a2bef3f2ef (parent: 797fe526-2433-40d1-ba7c-05f3f9173973) completed in 49.48s
2025-11-12 23:41:51,413 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:41:51,413 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 55
2025-11-12 23:41:51,414 - openevolve.database - INFO - Island Status:
2025-11-12 23:41:51,415 - openevolve.database - INFO -    Island 0: 29 programs, best=1.4995, avg=1.1463, diversity=608.27, gen=18 (best: ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f)
2025-11-12 23:41:51,415 - openevolve.database - INFO -    Island 1: 9 programs, best=1.4995, avg=1.3329, diversity=194.88, gen=18 (best: 2fa04697-34c4-4568-977e-e441b181285c)
2025-11-12 23:41:51,415 - openevolve.database - INFO -  * Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=18
2025-11-12 23:41:51,426 - openevolve.database - INFO - Saved database with 50 programs to openevolve_output/checkpoints/checkpoint_55
2025-11-12 23:41:51,427 - openevolve.controller - INFO - Saved best program at checkpoint 55 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:41:51,427 - openevolve.controller - INFO - Saved checkpoint at iteration 55 to openevolve_output/checkpoints/checkpoint_55
2025-11-12 23:42:20,390 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:42:20,393 - openevolve.evaluator - INFO - Evaluated program afb2b2b5-b0b7-479e-8cdc-d1777a7a9aed in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error=invalid syntax (tmpg2uwyezk.py, line 47)
2025-11-12 23:42:20,395 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:42:20,401 - openevolve.database - INFO - New MAP-Elites cell occupied in island 1: {'complexity': 4, 'diversity': 2}
2025-11-12 23:42:20,401 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:42:20,401 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:42:20,402 - openevolve.process_parallel - INFO - Iteration 57: Program afb2b2b5-b0b7-479e-8cdc-d1777a7a9aed (parent: ef9e4710-272e-4e62-b73b-dc2787ad5144) completed in 30.98s
2025-11-12 23:42:20,402 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=invalid syntax (tmpg2uwyezk.py, line 47)
2025-11-12 23:42:20,706 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:42:20,709 - openevolve.evaluator - INFO - Evaluated program 4ca88a05-da8a-4f3d-b136-8a1b52b565d6 in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error=invalid syntax (tmpgwf89xh8.py, line 47)
2025-11-12 23:42:20,711 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:42:20,717 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:42:20,717 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:42:20,717 - openevolve.process_parallel - INFO - Iteration 58: Program 4ca88a05-da8a-4f3d-b136-8a1b52b565d6 (parent: 7446cd28-1859-42ee-94e5-f107b978f765) completed in 29.30s
2025-11-12 23:42:20,717 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=invalid syntax (tmpgwf89xh8.py, line 47)
2025-11-12 23:42:39,350 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:42:42,618 - openevolve.evaluator - INFO - Evaluated program 6aef5af1-a275-4e6e-a640-4a6e8fa937c5 in 3.27s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:42:42,620 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:42:42,626 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 9, 'diversity': 9} (fitness: 1.500 -> 1.500)
2025-11-12 23:42:42,626 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:42:42,626 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:42:42,626 - openevolve.process_parallel - INFO - Iteration 56: Program 6aef5af1-a275-4e6e-a640-4a6e8fa937c5 (parent: 238b5b40-7d4f-4d9d-9b87-5a2d83bcd78a) completed in 88.19s
2025-11-12 23:42:42,627 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:42:59,268 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:43:02,431 - openevolve.evaluator - INFO - Evaluated program a237d501-00fd-43b0-9559-9e4fa04ff38b in 3.16s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:43:02,433 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:43:02,441 - openevolve.database - INFO - Island 1 MAP-Elites cell improved: {'complexity': 5, 'diversity': 2} (fitness: 1.500 -> 1.500)
2025-11-12 23:43:02,441 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:43:02,441 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:43:02,441 - openevolve.process_parallel - INFO - Iteration 59: Program a237d501-00fd-43b0-9559-9e4fa04ff38b (parent: 7446cd28-1859-42ee-94e5-f107b978f765) completed in 42.04s
2025-11-12 23:43:02,441 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:43:41,956 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:43:41,961 - openevolve.evaluator - INFO - Evaluated program acff272c-a243-4447-acf7-3ff4eafe19cb in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error=unsupported operand type(s) for -: 'tuple' and 'tuple'
2025-11-12 23:43:41,963 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:43:41,966 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:43:41,967 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:43:41,967 - openevolve.process_parallel - INFO - Iteration 60: Program acff272c-a243-4447-acf7-3ff4eafe19cb (parent: 7c4ad811-aa13-4b57-aeef-07fcc3ee56d8) completed in 81.25s
2025-11-12 23:43:41,967 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=unsupported operand type(s) for -: 'tuple' and 'tuple'
2025-11-12 23:43:41,967 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 60
2025-11-12 23:43:41,968 - openevolve.database - INFO - Island Status:
2025-11-12 23:43:41,968 - openevolve.database - INFO -    Island 0: 27 programs, best=1.4995, avg=1.2312, diversity=443.70, gen=21 (best: ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f)
2025-11-12 23:43:41,968 - openevolve.database - INFO -  * Island 1: 10 programs, best=1.4995, avg=1.1996, diversity=152.63, gen=20 (best: 2fa04697-34c4-4568-977e-e441b181285c)
2025-11-12 23:43:41,968 - openevolve.database - INFO -    Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=18
2025-11-12 23:43:41,979 - openevolve.database - INFO - Saved database with 50 programs to openevolve_output/checkpoints/checkpoint_60
2025-11-12 23:43:41,979 - openevolve.controller - INFO - Saved best program at checkpoint 60 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:43:41,979 - openevolve.controller - INFO - Saved checkpoint at iteration 60 to openevolve_output/checkpoints/checkpoint_60
2025-11-12 23:43:56,172 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:43:56,174 - openevolve.evaluator - INFO - Evaluated program 0eca8253-b0c6-4eeb-86fb-fff9928108d3 in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error=Missing run_search function
2025-11-12 23:43:56,177 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:43:56,180 - openevolve.database - INFO - New MAP-Elites cell occupied in island 1: {'complexity': 3, 'diversity': 0}
2025-11-12 23:43:56,180 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:43:56,180 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:43:56,180 - openevolve.process_parallel - INFO - Iteration 61: Program 0eca8253-b0c6-4eeb-86fb-fff9928108d3 (parent: 6dde66c8-e7ea-4596-9688-25a2bef3f2ef) completed in 73.55s
2025-11-12 23:43:56,180 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=Missing run_search function
2025-11-12 23:44:13,283 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:44:16,445 - openevolve.evaluator - INFO - Evaluated program 36d8c520-1244-483a-8a38-96edf031d593 in 3.16s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:44:16,449 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:44:16,458 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 4, 'diversity': 2} (fitness: 1.500 -> 1.500)
2025-11-12 23:44:16,459 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:44:16,459 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:44:16,459 - openevolve.process_parallel - INFO - Iteration 62: Program 36d8c520-1244-483a-8a38-96edf031d593 (parent: b7c17162-838e-43be-bf12-15ea6a8061a0) completed in 74.01s
2025-11-12 23:44:16,459 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:44:22,831 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:44:26,030 - openevolve.evaluator - INFO - Evaluated program 5a93308b-1bd7-4c9f-8647-4a23c120140c in 3.20s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:44:26,032 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:44:26,036 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:44:26,036 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:44:26,036 - openevolve.process_parallel - INFO - Iteration 63: Program 5a93308b-1bd7-4c9f-8647-4a23c120140c (parent: 7c476a23-ad51-4848-8c4f-3bb6bd0a0b7e) completed in 44.07s
2025-11-12 23:44:26,036 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:45:13,973 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:45:15,328 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:45:17,981 - openevolve.evaluator - INFO - Evaluated program 51cac72b-3de5-4695-8391-de5edf5abbbe in 4.01s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:45:17,984 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:45:17,992 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:45:17,992 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:45:17,992 - openevolve.process_parallel - INFO - Iteration 64: Program 51cac72b-3de5-4695-8391-de5edf5abbbe (parent: b7c17162-838e-43be-bf12-15ea6a8061a0) completed in 81.80s
2025-11-12 23:45:17,992 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:45:19,482 - openevolve.evaluator - INFO - Evaluated program 486a853e-9b00-4bcd-9e93-6766bce14301 in 4.15s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:45:19,484 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:45:19,492 - openevolve.database - INFO - Island 1 MAP-Elites cell improved: {'complexity': 3, 'diversity': 0} (fitness: 0.000 -> 1.500)
2025-11-12 23:45:19,492 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:45:19,492 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:45:19,492 - openevolve.process_parallel - INFO - Iteration 65: Program 486a853e-9b00-4bcd-9e93-6766bce14301 (parent: ef9e4710-272e-4e62-b73b-dc2787ad5144) completed in 63.03s
2025-11-12 23:45:19,492 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:45:19,492 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 65
2025-11-12 23:45:19,492 - openevolve.database - INFO - Island Status:
2025-11-12 23:45:19,492 - openevolve.database - INFO -  * Island 0: 27 programs, best=1.4995, avg=1.3423, diversity=0.00, gen=22 (best: ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f)
2025-11-12 23:45:19,492 - openevolve.database - INFO -    Island 1: 9 programs, best=1.4995, avg=1.4995, diversity=100.67, gen=21 (best: 2fa04697-34c4-4568-977e-e441b181285c)
2025-11-12 23:45:19,492 - openevolve.database - INFO -    Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=21
2025-11-12 23:45:19,503 - openevolve.database - INFO - Saved database with 50 programs to openevolve_output/checkpoints/checkpoint_65
2025-11-12 23:45:19,504 - openevolve.controller - INFO - Saved best program at checkpoint 65 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:45:19,504 - openevolve.controller - INFO - Saved checkpoint at iteration 65 to openevolve_output/checkpoints/checkpoint_65
2025-11-12 23:45:55,756 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:45:59,082 - openevolve.evaluator - INFO - Evaluated program 8103c3fd-2ade-475a-9d33-02cee300b216 in 3.32s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:45:59,084 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:45:59,086 - openevolve.database - INFO - Island 1 MAP-Elites cell improved: {'complexity': 5, 'diversity': 2} (fitness: 1.500 -> 1.500)
2025-11-12 23:45:59,086 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:45:59,086 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:45:59,086 - openevolve.process_parallel - INFO - Iteration 67: Program 8103c3fd-2ade-475a-9d33-02cee300b216 (parent: a237d501-00fd-43b0-9559-9e4fa04ff38b) completed in 41.10s
2025-11-12 23:45:59,087 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:45:59,114 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:45:59,115 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7120 input tokens (6000 > 12000 - 7120). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:46:04,151 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:46:04,152 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7120 input tokens (6000 > 12000 - 7120). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:46:09,189 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:46:09,190 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7120 input tokens (6000 > 12000 - 7120). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:46:09,882 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:46:13,210 - openevolve.evaluator - INFO - Evaluated program 392a31e3-a9aa-4bb5-83fe-55ec09ed2073 in 3.33s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:46:13,215 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:46:13,219 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 7, 'diversity': 6}
2025-11-12 23:46:13,219 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:46:13,219 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:46:13,219 - openevolve.process_parallel - INFO - Iteration 66: Program 392a31e3-a9aa-4bb5-83fe-55ec09ed2073 (parent: ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f) completed in 107.18s
2025-11-12 23:46:13,219 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:46:14,220 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:46:14,223 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7120 input tokens (6000 > 12000 - 7120). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:46:14,224 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7120 input tokens (6000 > 12000 - 7120). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:46:14,225 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:46:14,232 - openevolve.process_parallel - WARNING - Iteration 69 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7120 input tokens (6000 > 12000 - 7120). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:46:23,230 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:46:23,232 - openevolve.evaluator - INFO - Evaluated program f8cd1278-1200-4b75-adc9-56ec9ac704fc in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error=unmatched ')' (tmprruy_6y4.py, line 17)
2025-11-12 23:46:23,234 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:46:23,238 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:46:23,238 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:46:23,238 - openevolve.process_parallel - INFO - Iteration 68: Program f8cd1278-1200-4b75-adc9-56ec9ac704fc (parent: 664e9604-c959-490d-8e8f-5b4673ad95f5) completed in 63.75s
2025-11-12 23:46:23,239 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=unmatched ')' (tmprruy_6y4.py, line 17)
2025-11-12 23:47:08,164 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:47:08,169 - openevolve.evaluator - INFO - Evaluated program 01e65c62-e8a3-44c9-9894-59fff597074b in 0.00s: runs_successfully=0.0000, combined_score=0.0000, error=unsupported operand type(s) for -: 'tuple' and 'tuple'
2025-11-12 23:47:08,172 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:47:08,180 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:47:08,181 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:47:08,181 - openevolve.process_parallel - INFO - Iteration 70: Program 01e65c62-e8a3-44c9-9894-59fff597074b (parent: ed5fc0a7-5dd3-4997-882d-1a4a5efc54f2) completed in 54.96s
2025-11-12 23:47:08,181 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=unsupported operand type(s) for -: 'tuple' and 'tuple'
2025-11-12 23:47:08,181 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 70
2025-11-12 23:47:08,181 - openevolve.database - INFO - Island Status:
2025-11-12 23:47:08,181 - openevolve.database - INFO -    Island 0: 28 programs, best=1.4995, avg=1.3375, diversity=687.50, gen=24 (best: ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f)
2025-11-12 23:47:08,181 - openevolve.database - INFO -  * Island 1: 9 programs, best=1.4995, avg=1.4995, diversity=100.67, gen=23 (best: 2fa04697-34c4-4568-977e-e441b181285c)
2025-11-12 23:47:08,181 - openevolve.database - INFO -    Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=21
2025-11-12 23:47:08,196 - openevolve.database - INFO - Saved database with 50 programs to openevolve_output/checkpoints/checkpoint_70
2025-11-12 23:47:08,197 - openevolve.controller - INFO - Saved best program at checkpoint 70 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:47:08,197 - openevolve.controller - INFO - Saved checkpoint at iteration 70 to openevolve_output/checkpoints/checkpoint_70
2025-11-12 23:47:18,655 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:47:21,985 - openevolve.evaluator - INFO - Evaluated program f7aee1c9-8695-49f5-bd14-e5c0ca0956b8 in 3.33s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:47:21,986 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:47:21,987 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:47:21,987 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:47:21,987 - openevolve.process_parallel - INFO - Iteration 71: Program f7aee1c9-8695-49f5-bd14-e5c0ca0956b8 (parent: a237d501-00fd-43b0-9559-9e4fa04ff38b) completed in 67.76s
2025-11-12 23:47:21,987 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:47:22,012 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:47:22,012 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6135 input tokens (6000 > 12000 - 6135). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:47:27,041 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:47:27,041 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6135 input tokens (6000 > 12000 - 6135). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:47:32,072 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:47:32,072 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6135 input tokens (6000 > 12000 - 6135). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:47:37,104 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:47:37,105 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6135 input tokens (6000 > 12000 - 6135). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:47:37,105 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6135 input tokens (6000 > 12000 - 6135). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:47:37,107 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:47:37,115 - openevolve.process_parallel - WARNING - Iteration 74 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6135 input tokens (6000 > 12000 - 6135). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:47:47,608 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:47:50,847 - openevolve.evaluator - INFO - Evaluated program a214839c-ce7e-4877-893a-304e14507044 in 3.24s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:47:50,850 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:47:50,852 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:47:50,852 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:47:50,852 - openevolve.process_parallel - INFO - Iteration 72: Program a214839c-ce7e-4877-893a-304e14507044 (parent: 2cf7c89e-7adc-4bb1-b085-e67acad9bb00) completed in 87.61s
2025-11-12 23:47:50,852 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:47:50,884 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:47:50,885 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7305 input tokens (6000 > 12000 - 7305). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:47:55,919 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:47:55,920 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7305 input tokens (6000 > 12000 - 7305). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:00,951 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:00,954 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7305 input tokens (6000 > 12000 - 7305). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:05,988 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:05,989 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7305 input tokens (6000 > 12000 - 7305). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:05,989 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7305 input tokens (6000 > 12000 - 7305). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:05,991 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:48:05,993 - openevolve.process_parallel - WARNING - Iteration 76 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7305 input tokens (6000 > 12000 - 7305). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:06,017 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:06,018 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6316 input tokens (6000 > 12000 - 6316). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:11,052 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:11,053 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6316 input tokens (6000 > 12000 - 6316). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:16,087 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:16,088 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6316 input tokens (6000 > 12000 - 6316). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:20,616 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:48:21,127 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:21,127 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6316 input tokens (6000 > 12000 - 6316). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:21,128 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6316 input tokens (6000 > 12000 - 6316). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:21,130 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:48:21,136 - openevolve.process_parallel - WARNING - Iteration 77 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6316 input tokens (6000 > 12000 - 6316). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:21,160 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:21,161 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6685 input tokens (6000 > 12000 - 6685). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:23,503 - openevolve.evaluator - INFO - Evaluated program 1f1132fc-148f-4e09-9f4b-8977a7f7b7ea in 2.89s: runs_successfully=0.0000, combined_score=0.0000, error=unsupported operand type(s) for -: 'tuple' and 'tuple'
2025-11-12 23:48:23,505 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:48:23,513 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:48:23,513 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:48:23,513 - openevolve.process_parallel - INFO - Iteration 73: Program 1f1132fc-148f-4e09-9f4b-8977a7f7b7ea (parent: 620f4e43-41dc-4f5f-84ac-f7242c9cb9f2) completed in 75.33s
2025-11-12 23:48:23,513 - openevolve.process_parallel - INFO - Metrics: runs_successfully=0.0000, combined_score=0.0000, error=unsupported operand type(s) for -: 'tuple' and 'tuple'
2025-11-12 23:48:23,530 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:23,530 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6988 input tokens (6000 > 12000 - 6988). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:26,190 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:26,191 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6685 input tokens (6000 > 12000 - 6685). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:27,749 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:48:28,564 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:28,568 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6988 input tokens (6000 > 12000 - 6988). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:30,157 - openevolve.evaluator - INFO - Evaluated program 9009cd2d-7896-40d5-b27a-ecc71248e8f9 in 2.41s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:48:30,159 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:48:30,161 - openevolve.database - INFO - Island 1 MAP-Elites cell improved: {'complexity': 3, 'diversity': 0} (fitness: 1.500 -> 1.500)
2025-11-12 23:48:30,161 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:48:30,161 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:48:30,161 - openevolve.process_parallel - INFO - Iteration 75: Program 9009cd2d-7896-40d5-b27a-ecc71248e8f9 (parent: 486a853e-9b00-4bcd-9e93-6766bce14301) completed in 53.05s
2025-11-12 23:48:30,161 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:48:30,161 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 75
2025-11-12 23:48:30,161 - openevolve.database - INFO - Island Status:
2025-11-12 23:48:30,162 - openevolve.database - INFO -    Island 0: 26 programs, best=1.4995, avg=1.4008, diversity=0.00, gen=24 (best: ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f)
2025-11-12 23:48:30,162 - openevolve.database - INFO -    Island 1: 11 programs, best=1.4995, avg=1.4995, diversity=210.72, gen=24 (best: 2fa04697-34c4-4568-977e-e441b181285c)
2025-11-12 23:48:30,162 - openevolve.database - INFO -  * Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=24
2025-11-12 23:48:30,173 - openevolve.database - INFO - Saved database with 50 programs to openevolve_output/checkpoints/checkpoint_75
2025-11-12 23:48:30,173 - openevolve.controller - INFO - Saved best program at checkpoint 75 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:48:30,173 - openevolve.controller - INFO - Saved checkpoint at iteration 75 to openevolve_output/checkpoints/checkpoint_75
2025-11-12 23:48:30,184 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:30,184 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6603 input tokens (6000 > 12000 - 6603). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:31,222 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:31,223 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6685 input tokens (6000 > 12000 - 6685). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:33,598 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:33,598 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6988 input tokens (6000 > 12000 - 6988). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:35,213 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:35,213 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6603 input tokens (6000 > 12000 - 6603). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:36,253 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:36,253 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6685 input tokens (6000 > 12000 - 6685). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:36,254 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6685 input tokens (6000 > 12000 - 6685). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:36,255 - openevolve.process_parallel - WARNING - Iteration 78 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6685 input tokens (6000 > 12000 - 6685). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:36,255 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:48:36,280 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:36,280 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6595 input tokens (6000 > 12000 - 6595). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:38,629 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:38,629 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6988 input tokens (6000 > 12000 - 6988). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:38,630 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6988 input tokens (6000 > 12000 - 6988). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:38,632 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:48:38,634 - openevolve.process_parallel - WARNING - Iteration 79 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6988 input tokens (6000 > 12000 - 6988). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:40,242 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:40,245 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6603 input tokens (6000 > 12000 - 6603). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:41,309 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:41,310 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6595 input tokens (6000 > 12000 - 6595). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:45,276 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:45,279 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6603 input tokens (6000 > 12000 - 6603). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:45,279 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6603 input tokens (6000 > 12000 - 6603). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:45,280 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:48:45,288 - openevolve.process_parallel - WARNING - Iteration 80 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6603 input tokens (6000 > 12000 - 6603). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:45,307 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:45,308 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6403 input tokens (6000 > 12000 - 6403). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:46,338 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:46,339 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6595 input tokens (6000 > 12000 - 6595). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:50,336 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:50,337 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6403 input tokens (6000 > 12000 - 6403). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:51,368 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:51,369 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6595 input tokens (6000 > 12000 - 6595). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:51,369 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6595 input tokens (6000 > 12000 - 6595). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:51,370 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:48:51,374 - openevolve.process_parallel - WARNING - Iteration 81 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6595 input tokens (6000 > 12000 - 6595). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:48:51,396 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:51,396 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7294 input tokens (6000 > 12000 - 7294). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:55,366 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:55,366 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6403 input tokens (6000 > 12000 - 6403). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:48:56,426 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:48:56,426 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7294 input tokens (6000 > 12000 - 7294). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:00,395 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:00,396 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6403 input tokens (6000 > 12000 - 6403). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:00,396 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6403 input tokens (6000 > 12000 - 6403). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:00,397 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:49:00,398 - openevolve.process_parallel - WARNING - Iteration 83 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6403 input tokens (6000 > 12000 - 6403). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:00,423 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:00,423 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7141 input tokens (6000 > 12000 - 7141). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:01,458 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:01,458 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7294 input tokens (6000 > 12000 - 7294). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:05,452 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:05,453 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7141 input tokens (6000 > 12000 - 7141). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:06,158 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:49:06,496 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:06,496 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7294 input tokens (6000 > 12000 - 7294). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:06,497 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7294 input tokens (6000 > 12000 - 7294). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:06,498 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:49:06,501 - openevolve.process_parallel - WARNING - Iteration 84 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7294 input tokens (6000 > 12000 - 7294). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:06,528 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:06,529 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7674 input tokens (6000 > 12000 - 7674). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:08,609 - openevolve.evaluator - INFO - Evaluated program cd81f06f-d2c6-4cc7-873e-7539a390fc68 in 2.45s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:49:08,610 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:49:08,611 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 4, 'diversity': 2} (fitness: 1.500 -> 1.500)
2025-11-12 23:49:08,611 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:49:08,611 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:49:08,611 - openevolve.process_parallel - INFO - Iteration 82: Program cd81f06f-d2c6-4cc7-873e-7539a390fc68 (parent: 0cc1e0fe-1e97-4bbd-abf9-01bf6ca9cadc) completed in 29.98s
2025-11-12 23:49:08,611 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:49:08,638 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:08,638 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6643 input tokens (6000 > 12000 - 6643). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:10,484 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:10,487 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7141 input tokens (6000 > 12000 - 7141). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:11,562 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:11,562 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7674 input tokens (6000 > 12000 - 7674). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:13,667 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:13,668 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6643 input tokens (6000 > 12000 - 6643). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:15,517 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:15,520 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7141 input tokens (6000 > 12000 - 7141). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:15,520 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7141 input tokens (6000 > 12000 - 7141). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:15,522 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:49:15,525 - openevolve.process_parallel - WARNING - Iteration 85 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7141 input tokens (6000 > 12000 - 7141). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:15,546 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:15,547 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6949 input tokens (6000 > 12000 - 6949). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:16,592 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:16,593 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7674 input tokens (6000 > 12000 - 7674). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:18,697 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:18,697 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6643 input tokens (6000 > 12000 - 6643). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:20,576 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:20,579 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6949 input tokens (6000 > 12000 - 6949). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:21,622 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:21,622 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7674 input tokens (6000 > 12000 - 7674). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:21,623 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7674 input tokens (6000 > 12000 - 7674). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:21,625 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:49:21,630 - openevolve.process_parallel - WARNING - Iteration 86 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7674 input tokens (6000 > 12000 - 7674). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:21,651 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:21,652 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6250 input tokens (6000 > 12000 - 6250). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:23,726 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:23,726 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6643 input tokens (6000 > 12000 - 6643). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:23,727 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6643 input tokens (6000 > 12000 - 6643). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:23,729 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:49:23,736 - openevolve.process_parallel - WARNING - Iteration 87 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6643 input tokens (6000 > 12000 - 6643). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:25,608 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:25,609 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6949 input tokens (6000 > 12000 - 6949). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:26,681 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:26,682 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6250 input tokens (6000 > 12000 - 6250). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:30,641 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:30,641 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6949 input tokens (6000 > 12000 - 6949). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:30,642 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6949 input tokens (6000 > 12000 - 6949). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:30,643 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:49:30,644 - openevolve.process_parallel - WARNING - Iteration 88 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6949 input tokens (6000 > 12000 - 6949). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:30,667 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:30,668 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6577 input tokens (6000 > 12000 - 6577). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:31,711 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:31,711 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6250 input tokens (6000 > 12000 - 6250). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:35,698 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:35,699 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6577 input tokens (6000 > 12000 - 6577). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:36,740 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:36,741 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6250 input tokens (6000 > 12000 - 6250). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:36,741 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6250 input tokens (6000 > 12000 - 6250). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:36,742 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:49:36,748 - openevolve.process_parallel - WARNING - Iteration 89 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6250 input tokens (6000 > 12000 - 6250). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:36,770 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:36,770 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7400 input tokens (6000 > 12000 - 7400). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:40,728 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:40,731 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6577 input tokens (6000 > 12000 - 6577). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:41,802 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:41,803 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7400 input tokens (6000 > 12000 - 7400). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:45,764 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:45,765 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6577 input tokens (6000 > 12000 - 6577). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:45,766 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6577 input tokens (6000 > 12000 - 6577). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:45,767 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:49:45,769 - openevolve.process_parallel - WARNING - Iteration 91 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6577 input tokens (6000 > 12000 - 6577). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:45,792 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:45,792 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6403 input tokens (6000 > 12000 - 6403). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:46,834 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:46,834 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7400 input tokens (6000 > 12000 - 7400). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:50,822 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:50,826 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6403 input tokens (6000 > 12000 - 6403). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:51,867 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:51,867 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7400 input tokens (6000 > 12000 - 7400). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:51,868 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7400 input tokens (6000 > 12000 - 7400). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:51,869 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:49:51,875 - openevolve.process_parallel - WARNING - Iteration 92 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7400 input tokens (6000 > 12000 - 7400). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:49:51,894 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:51,895 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6531 input tokens (6000 > 12000 - 6531). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:55,857 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:55,857 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6403 input tokens (6000 > 12000 - 6403). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:49:56,924 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:49:56,925 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6531 input tokens (6000 > 12000 - 6531). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:50:00,886 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:00,887 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6403 input tokens (6000 > 12000 - 6403). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:00,887 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6403 input tokens (6000 > 12000 - 6403). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:00,889 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:50:00,897 - openevolve.process_parallel - WARNING - Iteration 93 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6403 input tokens (6000 > 12000 - 6403). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:01,955 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:01,955 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6531 input tokens (6000 > 12000 - 6531). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:50:06,985 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:06,985 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6531 input tokens (6000 > 12000 - 6531). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:06,986 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6531 input tokens (6000 > 12000 - 6531). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:06,987 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:50:06,991 - openevolve.process_parallel - WARNING - Iteration 94 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6531 input tokens (6000 > 12000 - 6531). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:07,012 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:07,013 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6808 input tokens (6000 > 12000 - 6808). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:50:12,043 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:12,044 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6808 input tokens (6000 > 12000 - 6808). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:50:17,073 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:17,074 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6808 input tokens (6000 > 12000 - 6808). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:50:21,844 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:50:22,118 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:22,118 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6808 input tokens (6000 > 12000 - 6808). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:22,119 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6808 input tokens (6000 > 12000 - 6808). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:22,121 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:50:22,122 - openevolve.process_parallel - WARNING - Iteration 96 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6808 input tokens (6000 > 12000 - 6808). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:22,149 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:22,149 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6688 input tokens (6000 > 12000 - 6688). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:50:25,068 - openevolve.evaluator - INFO - Evaluated program a4392fa2-7cc4-4ca8-af43-dd44f3730e35 in 3.22s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:50:25,070 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:50:25,077 - openevolve.database - INFO - New MAP-Elites cell occupied in island 0: {'complexity': 8, 'diversity': 8}
2025-11-12 23:50:25,078 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:50:25,078 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:50:25,078 - openevolve.process_parallel - INFO - Iteration 90: Program a4392fa2-7cc4-4ca8-af43-dd44f3730e35 (parent: b7c17162-838e-43be-bf12-15ea6a8061a0) completed in 61.34s
2025-11-12 23:50:25,078 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:50:25,078 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 90
2025-11-12 23:50:25,078 - openevolve.database - INFO - Island Status:
2025-11-12 23:50:25,078 - openevolve.database - INFO -  * Island 0: 26 programs, best=1.4995, avg=1.4188, diversity=0.00, gen=26 (best: ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f)
2025-11-12 23:50:25,078 - openevolve.database - INFO -    Island 1: 11 programs, best=1.4995, avg=1.4995, diversity=210.72, gen=24 (best: 2fa04697-34c4-4568-977e-e441b181285c)
2025-11-12 23:50:25,078 - openevolve.database - INFO -    Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=24
2025-11-12 23:50:25,093 - openevolve.database - INFO - Saved database with 50 programs to openevolve_output/checkpoints/checkpoint_90
2025-11-12 23:50:25,093 - openevolve.controller - INFO - Saved best program at checkpoint 90 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:50:25,093 - openevolve.controller - INFO - Saved checkpoint at iteration 90 to openevolve_output/checkpoints/checkpoint_90
2025-11-12 23:50:25,099 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:25,099 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6748 input tokens (6000 > 12000 - 6748). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:50:27,180 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:27,181 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6688 input tokens (6000 > 12000 - 6688). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:50:30,129 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:30,130 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6748 input tokens (6000 > 12000 - 6748). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:50:32,210 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:32,211 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6688 input tokens (6000 > 12000 - 6688). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:50:35,160 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:35,160 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6748 input tokens (6000 > 12000 - 6748). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:50:37,241 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:37,241 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6688 input tokens (6000 > 12000 - 6688). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:37,242 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6688 input tokens (6000 > 12000 - 6688). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:37,243 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:50:37,248 - openevolve.process_parallel - WARNING - Iteration 97 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6688 input tokens (6000 > 12000 - 6688). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:40,197 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:40,200 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6748 input tokens (6000 > 12000 - 6748). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:40,201 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6748 input tokens (6000 > 12000 - 6748). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:40,203 - openevolve.llm.ensemble - INFO - Sampled model: RedHatAI/Meta-Llama-3.1-8B-Instruct-FP8
2025-11-12 23:50:40,205 - openevolve.process_parallel - WARNING - Iteration 98 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 6748 input tokens (6000 > 12000 - 6748). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:40,234 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:40,235 - openevolve.llm.openai - WARNING - Error on attempt 1/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7072 input tokens (6000 > 12000 - 7072). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:50:45,264 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:45,268 - openevolve.llm.openai - WARNING - Error on attempt 2/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7072 input tokens (6000 > 12000 - 7072). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:50:50,298 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:50,299 - openevolve.llm.openai - WARNING - Error on attempt 3/4: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7072 input tokens (6000 > 12000 - 7072). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}. Retrying...
2025-11-12 23:50:55,328 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-11-12 23:50:55,329 - openevolve.llm.openai - ERROR - All 4 attempts failed with error: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7072 input tokens (6000 > 12000 - 7072). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:55,329 - openevolve.process_parallel - ERROR - LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7072 input tokens (6000 > 12000 - 7072). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:55,332 - openevolve.process_parallel - WARNING - Iteration 100 error: LLM generation failed: Error code: 400 - {'error': {'message': "'max_tokens' or 'max_completion_tokens' is too large: 6000. This model's maximum context length is 12000 tokens and your request has 7072 input tokens (6000 > 12000 - 7072). None", 'type': 'BadRequestError', 'param': None, 'code': 400}}
2025-11-12 23:50:58,449 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:51:01,737 - openevolve.evaluator - INFO - Evaluated program 5a8bbaa4-2844-44fa-b282-e7f6c5aafb9e in 3.29s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:51:01,741 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 8, 'diversity': 8} (fitness: 1.500 -> 1.500)
2025-11-12 23:51:01,741 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:51:01,741 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:51:01,741 - openevolve.process_parallel - INFO - Iteration 95: Program 5a8bbaa4-2844-44fa-b282-e7f6c5aafb9e (parent: f7918a9e-8920-4ce0-9fb6-6a79189bde5b) completed in 60.85s
2025-11-12 23:51:01,741 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:51:01,741 - openevolve.process_parallel - INFO - Checkpoint interval reached at iteration 95
2025-11-12 23:51:01,742 - openevolve.database - INFO - Island Status:
2025-11-12 23:51:01,742 - openevolve.database - INFO -  * Island 0: 25 programs, best=1.4995, avg=1.4261, diversity=233.88, gen=27 (best: ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f)
2025-11-12 23:51:01,742 - openevolve.database - INFO -    Island 1: 11 programs, best=1.4995, avg=1.4995, diversity=210.72, gen=24 (best: 2fa04697-34c4-4568-977e-e441b181285c)
2025-11-12 23:51:01,742 - openevolve.database - INFO -    Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=24
2025-11-12 23:51:01,753 - openevolve.database - INFO - Saved database with 50 programs to openevolve_output/checkpoints/checkpoint_95
2025-11-12 23:51:01,753 - openevolve.controller - INFO - Saved best program at checkpoint 95 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:51:01,753 - openevolve.controller - INFO - Saved checkpoint at iteration 95 to openevolve_output/checkpoints/checkpoint_95
2025-11-12 23:51:35,795 - httpx - INFO - HTTP Request: POST http://localhost:8000/v1/chat/completions "HTTP/1.1 200 OK"
2025-11-12 23:51:38,217 - openevolve.evaluator - INFO - Evaluated program 13af43bd-64c1-4fbb-9df2-645011ae6d35 in 2.42s: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:51:38,222 - openevolve.database - INFO - Island 0 MAP-Elites cell improved: {'complexity': 9, 'diversity': 9} (fitness: 1.500 -> 1.500)
2025-11-12 23:51:38,222 - openevolve.database - INFO - Population size (51) exceeds limit (50), removing 1 programs
2025-11-12 23:51:38,222 - openevolve.database - INFO - Population size after cleanup: 50
2025-11-12 23:51:38,222 - openevolve.process_parallel - INFO - Iteration 99: Program 13af43bd-64c1-4fbb-9df2-645011ae6d35 (parent: 6330d97a-726b-4dab-8293-cd09ac328868) completed in 60.97s
2025-11-12 23:51:38,222 - openevolve.process_parallel - INFO - Metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:51:38,222 - openevolve.process_parallel - INFO - âœ… Evolution completed - Maximum iterations reached
2025-11-12 23:51:38,234 - openevolve.database - INFO - Saved database with 50 programs to openevolve_output/checkpoints/checkpoint_100
2025-11-12 23:51:38,234 - openevolve.controller - INFO - Saved best program at checkpoint 100 with metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:51:38,234 - openevolve.controller - INFO - Saved checkpoint at iteration 100 to openevolve_output/checkpoints/checkpoint_100
2025-11-12 23:51:38,242 - openevolve.process_parallel - INFO - Stopped process pool
2025-11-12 23:51:38,243 - openevolve.controller - INFO - Using tracked best program: ce0b1b40-47f9-45ff-b6e8-46bb6d0bb55f
2025-11-12 23:51:38,243 - openevolve.controller - INFO - Evolution complete. Best program has metrics: runs_successfully=1.0000, value_score=0.9997, distance_score=0.9995, combined_score=1.4995, reliability_score=1.0000
2025-11-12 23:51:38,243 - openevolve.controller - INFO - Saved best program to openevolve_output/best/best_program.py with program info to openevolve_output/best/best_program_info.json
