{"id": "91708979-8fc2-4049-a650-6073c1f64955", "code": "from dataclasses import dataclass\n\n@dataclass\nclass Triple:\n    subject: str\n    predicate: str\n    object: str\n\n# EVOLVE-BLOCK-START\n\ndef predict(triples: list[Triple]) -> str:\n    \"\"\"\n    Generates a natural language sentence from a list of triples.\n    \"\"\"\n    if not triples:\n        return \"\"\n\n    sentence = \"\"\n    subject = triples[0].subject\n\n    for i, triple in enumerate(triples):\n        predicate = triple.predicate\n        object_value = triple.object\n\n        if i == 0:\n            sentence += f\"{subject} \"\n            if predicate == \"alternativeName\":\n                sentence += f\"is also known as {object_value}. \"\n            elif predicate == \"bodyStyle\":\n                sentence += f\"has a {object_value} body style. \"\n            elif predicate == \"engine\":\n                sentence += f\"is powered by a {object_value}. \"\n            elif predicate == \"manufacturer\":\n                sentence += f\"is manufactured by {object_value}. \"\n            elif predicate == \"relatedMeanOfTransportation\":\n                sentence += f\"is related to {object_value}. \"\n            elif predicate == \"transmission\":\n                sentence += f\"features a {object_value} transmission. \"\n            elif predicate == \"wheelbase\":\n                sentence += f\"has a wheelbase of {object_value}. \"\n            elif predicate == \"builder\":\n                sentence += f\"was built by {object_value}. \"\n            elif predicate == \"completionDate\":\n                sentence += f\"was completed on {object_value}. \"\n            elif predicate == \"length\":\n                sentence += f\"has a length of {object_value}. \"\n            elif predicate == \"powerType\":\n                sentence += f\"is powered by {object_value}. \"\n            elif predicate == \"shipClass\":\n                sentence += f\"is a {object_value}. \"\n            elif predicate == \"shipDisplacement\":\n                sentence += f\"has a displacement of {object_value}. \"\n            elif predicate == \"shipLaunch\":\n                sentence += f\"was launched on {object_value}. \"\n            elif predicate == \"shipOrdered\":\n                sentence += f\"was ordered on {object_value}. \"\n            elif predicate == \"shipPower\":\n                sentence += f\"is powered by {object_value}. \"\n            elif predicate == \"topSpeed\":\n                sentence += f\"has a top speed of {object_value}. \"\n            elif predicate == \"location\":\n                sentence += f\"is located in {object_value}. \"\n            elif predicate == \"christeningDate\":\n                sentence += f\"was christened on {object_value}. \"\n            elif predicate == \"maidenVoyage\":\n                sentence += f\"had its maiden voyage on {object_value}. \"\n            elif predicate == \"owner\":\n                sentence += f\"is owned by {object_value}. \"\n            elif predicate == \"shipBeam\":\n                sentence += f\"has a beam of {object_value}. \"\n            elif predicate == \"shipInService\":\n                sentence += f\"entered service on {object_value}. \"\n            elif predicate == \"status\":\n                sentence += f\"is currently {object_value}. \"\n            elif predicate == \"activeYearsStartDate\":\n                sentence += f\"started its active years in {object_value}. \"\n            elif predicate == \"shipLaidDown\":\n                sentence += f\"was laid down on {object_value}. \"\n            elif predicate == \"buildDate\":\n                sentence += f\"was built between {object_value}. \"\n            elif predicate == \"cylinderCount\":\n                sentence += f\"has {object_value} cylinders. \"\n            elif predicate == \"totalProduction\":\n                sentence += f\"had a total production of {object_value}. \"\n            elif predicate == \"countryOrigin\":\n                sentence += f\"originated from {object_value}. \"\n            elif predicate == \"diameter\":\n                sentence += f\"has a diameter of {object_value}. \"\n            elif predicate == \"failedLaunches\":\n                sentence += f\"had {object_value} failed launches. \"\n            elif predicate == \"rocketStages\":\n                sentence += f\"has {object_value} rocket stages. \"\n            elif predicate == \"totalLaunches\":\n                sentence += f\"had a total of {object_value} launches. \"\n            elif predicate == \"assembly\":\n                sentence += f\"was assembled in {object_value}. \"\n            elif predicate == \"class\":\n                sentence += f\"is a {object_value}. \"\n            elif predicate == \"designer\":\n                sentence += f\"was designed by {object_value}. \"\n            elif predicate == \"modelYears\":\n                sentence += f\"was produced in {object_value}. \"\n            elif predicate == \"country\":\n                sentence += f\"is in {object_value}. \"\n            elif predicate == \"foundationPlace\":\n                sentence += f\"was founded in {object_value}. \"\n            elif predicate == \"foundedBy\":\n                sentence += f\"was founded by {object_value}. \"\n            elif predicate == \"designCompany\":\n                sentence += f\"was designed by {object_value}. \"\n            elif predicate == \"productionStartYear\":\n                sentence += f\"started production in {object_value}. \"\n            elif predicate == \"width\":\n                sentence += f\"has a width of {object_value}. \"\n            elif predicate == \"layout\":\n                sentence += f\"has a {object_value} layout. \"\n            elif predicate == \"parentCompany\":\n                sentence += f\"is a subsidiary of {object_value}. \"\n            elif predicate == \"operator\":\n                sentence += f\"is operated by {object_value}. \"\n            elif predicate == \"product\":\n                sentence += f\"produces {object_value}. \"\n            elif predicate == \"city\":\n                sentence += f\"is located in {object_value}. \"\n            elif predicate == \"successor\":\n                sentence += f\"was succeeded by {object_value}. \"\n            elif predicate == \"fate\":\n                sentence += f\"became {object_value}. \"\n            elif predicate == \"keyPerson\":\n                sentence += f\"was led by {object_value}. \"\n            elif predicate == \"subsidiary\":\n                sentence += f\"has a subsidiary {object_value}. \"\n            elif predicate == \"comparable\":\n                sentence += f\"is comparable to {object_value}. \"\n            elif predicate == \"finalFlight\":\n                sentence += f\"had its final flight on {object_value}. \"\n            elif predicate == \"function\":\n                sentence += f\"functions as {object_value}. \"\n            elif predicate == \"launchSite\":\n                sentence += f\"launches from {object_value}. \"\n            elif predicate == \"maidenFlight\":\n                sentence += f\"had its maiden flight on {object_value}. \"\n            elif predicate == \"capital\":\n                sentence += f\"has a capital of {object_value}. \"\n            elif predicate == \"demonym\":\n                sentence += f\"its people are known as {object_value}. \"\n            elif predicate == \"leader\":\n                sentence += f\"is led by {object_value}. \"\n            elif predicate == \"partialFailures\":\n                sentence += f\"had {object_value} partial failures. \"\n            elif predicate == \"site\":\n                sentence += f\"is located at {object_value}. \"\n            elif predicate == \"headquarter\":\n                sentence += f\"is headquartered in {object_value}. \"\n            elif predicate == \"associatedRocket\":\n                sentence += f\"is associated with {object_value}. \"\n            elif predicate == \"saint\":\n                sentence += f\"is the patron saint of {object_value}. \"\n            elif predicate == \"employer\":\n                sentence += f\"was employed by {object_value}. \"\n            elif predicate == \"ethnicGroup\":\n                sentence += f\"includes {object_value}. \"\n            elif predicate == \"language\":\n                sentence += f\"speaks {object_value}. \"\n            elif predicate == \"leaderTitle\":\n                sentence += f\"has a leader with the title of {object_value}. \"\n            elif predicate == \"anthem\":\n                sentence += f\"has an anthem of {object_value}. \"\n            elif predicate == \"productionEndYear\":\n                sentence += f\"ended production in {object_value}. \"\n            elif predicate == \"division\":\n                sentence += f\"has a division {object_value}. \"\n            elif predicate == \"shipDraft\":\n                sentence += f\"has a draft of {object_value}. \"\n            elif predicate == \"modelStartYear\":\n                sentence += f\"started production in {object_value}. \"\n\n    return sentence\n\n# EVOLVE-BLOCK-END", "language": "python", "parent_id": "b6b03db8-3df5-44b9-abab-33b54ad50e29", "generation": 1, "timestamp": 1769457130.553788, "iteration_found": 6, "metrics": {"combined_score": 0.194804592608036}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 2 lines with 168 lines", "parent_metrics": {"combined_score": 0.10981851510900303}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert in fixing your collegues code. You know that the code should be in format:\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly, indentations and endlines as well)\n=======\n# New replacement code\n>>>>>>> REPLACE\nProvided the incorrect format of SEARCH/REPLACE fix it to a correct format.\n        ", "user": "An incorrect diff format was detected in this change:\nHere's a suggested improvement to handle multiple triples and create a more complex sentence:\n\n```diff\n<<<<<<< SEARCH\ndef predict(triples: list[Triple]) -> str:\n    return f\"The {triples[0].predicate} of {triples[0].subject} is {triples[0].object}.\"\n=======\ndef predict(triples: list[Triple]) -> str:\n    \"\"\"\n    Generates a natural language sentence from a list of triples.\n    \"\"\"\n    if not triples:\n        return \"\"\n\n    sentence = \"\"\n    subject = triples[0].subject\n\n    for i, triple in enumerate(triples):\n        predicate = triple.predicate\n        object_value = triple.object\n\n        if i == 0:\n            sentence += f\"{subject} \"\n            if predicate == \"alternativeName\":\n                sentence += f\"is also known as {object_value}. \"\n            elif predicate == \"bodyStyle\":\n                sentence += f\"has a {object_value} body style. \"\n            elif predicate == \"engine\":\n                sentence += f\"is powered by a {object_value}. \"\n            elif predicate == \"manufacturer\":\n                sentence += f\"is manufactured by {object_value}. \"\n            elif predicate == \"relatedMeanOfTransportation\":\n                sentence += f\"is related to {object_value}. \"\n            elif predicate == \"transmission\":\n                sentence += f\"features a {object_value} transmission. \"\n            elif predicate == \"wheelbase\":\n                sentence += f\"has a wheelbase of {object_value}. \"\n            elif predicate == \"builder\":\n                sentence += f\"was built by {object_value}. \"\n            elif predicate == \"completionDate\":\n                sentence += f\"was completed on {object_value}. \"\n            elif predicate == \"length\":\n                sentence += f\"has a length of {object_value}. \"\n            elif predicate == \"powerType\":\n                sentence += f\"is powered by {object_value}. \"\n            elif predicate == \"shipClass\":\n                sentence += f\"is a {object_value}. \"\n            elif predicate == \"shipDisplacement\":\n                sentence += f\"has a displacement of {object_value}. \"\n            elif predicate == \"shipLaunch\":\n                sentence += f\"was launched on {object_value}. \"\n            elif predicate == \"shipOrdered\":\n                sentence += f\"was ordered on {object_value}. \"\n            elif predicate == \"shipPower\":\n                sentence += f\"is powered by {object_value}. \"\n            elif predicate == \"topSpeed\":\n                sentence += f\"has a top speed of {object_value}. \"\n            elif predicate == \"location\":\n                sentence += f\"is located in {object_value}. \"\n            elif predicate == \"christeningDate\":\n                sentence += f\"was christened on {object_value}. \"\n            elif predicate == \"maidenVoyage\":\n                sentence += f\"had its maiden voyage on {object_value}. \"\n            elif predicate == \"owner\":\n                sentence += f\"is owned by {object_value}. \"\n            elif predicate == \"shipBeam\":\n                sentence += f\"has a beam of {object_value}. \"\n            elif predicate == \"shipInService\":\n                sentence += f\"entered service on {object_value}. \"\n            elif predicate == \"status\":\n                sentence += f\"is currently {object_value}. \"\n            elif predicate == \"activeYearsStartDate\":\n                sentence += f\"started its active years in {object_value}. \"\n            elif predicate == \"shipLaidDown\":\n                sentence += f\"was laid down on {object_value}. \"\n            elif predicate == \"buildDate\":\n                sentence += f\"was built between {object_value}. \"\n            elif predicate == \"cylinderCount\":\n                sentence += f\"has {object_value} cylinders. \"\n            elif predicate == \"totalProduction\":\n                sentence += f\"had a total production of {object_value}. \"\n            elif predicate == \"countryOrigin\":\n                sentence += f\"originated from {object_value}. \"\n            elif predicate == \"diameter\":\n                sentence += f\"has a diameter of {object_value}. \"\n            elif predicate == \"failedLaunches\":\n                sentence += f\"had {object_value} failed launches. \"\n            elif predicate == \"rocketStages\":\n                sentence += f\"has {object_value} rocket stages. \"\n            elif predicate == \"totalLaunches\":\n                sentence += f\"had a total of {object_value} launches. \"\n            elif predicate == \"assembly\":\n                sentence += f\"was assembled in {object_value}. \"\n            elif predicate == \"class\":\n                sentence += f\"is a {object_value}. \"\n            elif predicate == \"designer\":\n                sentence += f\"was designed by {object_value}. \"\n            elif predicate == \"modelYears\":\n                sentence += f\"was produced in {object_value}. \"\n            elif predicate == \"country\":\n                sentence += f\"is in {object_value}. \"\n            elif predicate == \"foundationPlace\":\n                sentence += f\"was founded in {object_value}. \"\n            elif predicate == \"foundedBy\":\n                sentence += f\"was founded by {object_value}. \"\n            elif predicate == \"designCompany\":\n                sentence += f\"was designed by {object_value}. \"\n            elif predicate == \"productionStartYear\":\n                sentence += f\"started production in {object_value}. \"\n            elif predicate == \"width\":\n                sentence += f\"has a width of {object_value}. \"\n            elif predicate == \"layout\":\n                sentence += f\"has a {object_value} layout. \"\n            elif predicate == \"parentCompany\":\n                sentence += f\"is a subsidiary of {object_value}. \"\n            elif predicate == \"operator\":\n                sentence += f\"is operated by {object_value}. \"\n            elif predicate == \"product\":\n                sentence += f\"produces {object_value}. \"\n            elif predicate == \"city\":\n                sentence += f\"is located in {object_value}. \"\n            elif predicate == \"successor\":\n                sentence += f\"was succeeded by {object_value}. \"\n            elif predicate == \"fate\":\n                sentence += f\"became {object_value}. \"\n            elif predicate == \"keyPerson\":\n                sentence += f\"was led by {object_value}. \"\n            elif predicate == \"subsidiary\":\n                sentence += f\"has a subsidiary {object_value}. \"\n            elif predicate == \"comparable\":\n                sentence += f\"is comparable to {object_value}. \"\n            elif predicate == \"finalFlight\":\n                sentence += f\"had its final flight on {object_value}. \"\n            elif predicate == \"function\":\n                sentence += f\"functions as {object_value}. \"\n            elif predicate == \"launchSite\":\n                sentence += f\"launches from {object_value}. \"\n            elif predicate == \"maidenFlight\":\n                sentence += f\"had its maiden flight on {object_value}. \"\n            elif predicate == \"capital\":\n                sentence += f\"has a capital of {object_value}. \"\n            elif predicate == \"demonym\":\n                sentence += f\"its people are known as {object_value}. \"\n            elif predicate == \"leader\":\n                sentence += f\"is led by {object_value}. \"\n            elif predicate == \"partialFailures\":\n                sentence += f\"had {object_value} partial failures. \"\n            elif predicate == \"site\":\n                sentence += f\"is located at {object_value}. \"\n            elif predicate == \"headquarter\":\n                sentence += f\"is headquartered in {object_value}. \"\n            elif predicate == \"associatedRocket\":\n                sentence += f\"is associated with {object_value}. \"\n            elif predicate == \"saint\":\n                sentence += f\"is the patron saint of {object_value}. \"\n            elif predicate == \"employer\":\n                sentence += f\"was employed by {object_value}. \"\n            elif predicate == \"ethnicGroup\":\n                sentence += f\"includes {object_value}. \"\n            elif predicate == \"language\":\n                sentence += f\"speaks {object_value}. \"\n            elif predicate == \"leaderTitle\":\n                sentence += f\"has a leader with the title of {object_value}. \"\n            elif predicate == \"anthem\":\n                sentence += f\"has an anthem of {object_value}. \"\n            elif predicate == \"productionEndYear\":\n                sentence += f\"ended production in {object_value}. \"\n            elif predicate == \"division\":\n                sentence += f\"has a division {object_value}. \"\n            elif predicate == \"shipDraft\":\n                sentence += f\"has a draft of {object_value}. \"\n            elif predicate == \"modelStartYear\":\n                sentence += f\"started production in {object_value}. \"\n        \nPlease fix it to the correct format.", "responses": ["```diff\n<<<<<<< SEARCH\ndef predict(triples: list[Triple]) -> str:\n    return f\"The {triples[0].predicate} of {triples[0].subject} is {triples[0].object}.\"\n=======\ndef predict(triples: list[Triple]) -> str:\n    \"\"\"\n    Generates a natural language sentence from a list of triples.\n    \"\"\"\n    if not triples:\n        return \"\"\n\n    sentence = \"\"\n    subject = triples[0].subject\n\n    for i, triple in enumerate(triples):\n        predicate = triple.predicate\n        object_value = triple.object\n\n        if i == 0:\n            sentence += f\"{subject} \"\n            if predicate == \"alternativeName\":\n                sentence += f\"is also known as {object_value}. \"\n            elif predicate == \"bodyStyle\":\n                sentence += f\"has a {object_value} body style. \"\n            elif predicate == \"engine\":\n                sentence += f\"is powered by a {object_value}. \"\n            elif predicate == \"manufacturer\":\n                sentence += f\"is manufactured by {object_value}. \"\n            elif predicate == \"relatedMeanOfTransportation\":\n                sentence += f\"is related to {object_value}. \"\n            elif predicate == \"transmission\":\n                sentence += f\"features a {object_value} transmission. \"\n            elif predicate == \"wheelbase\":\n                sentence += f\"has a wheelbase of {object_value}. \"\n            elif predicate == \"builder\":\n                sentence += f\"was built by {object_value}. \"\n            elif predicate == \"completionDate\":\n                sentence += f\"was completed on {object_value}. \"\n            elif predicate == \"length\":\n                sentence += f\"has a length of {object_value}. \"\n            elif predicate == \"powerType\":\n                sentence += f\"is powered by {object_value}. \"\n            elif predicate == \"shipClass\":\n                sentence += f\"is a {object_value}. \"\n            elif predicate == \"shipDisplacement\":\n                sentence += f\"has a displacement of {object_value}. \"\n            elif predicate == \"shipLaunch\":\n                sentence += f\"was launched on {object_value}. \"\n            elif predicate == \"shipOrdered\":\n                sentence += f\"was ordered on {object_value}. \"\n            elif predicate == \"shipPower\":\n                sentence += f\"is powered by {object_value}. \"\n            elif predicate == \"topSpeed\":\n                sentence += f\"has a top speed of {object_value}. \"\n            elif predicate == \"location\":\n                sentence += f\"is located in {object_value}. \"\n            elif predicate == \"christeningDate\":\n                sentence += f\"was christened on {object_value}. \"\n            elif predicate == \"maidenVoyage\":\n                sentence += f\"had its maiden voyage on {object_value}. \"\n            elif predicate == \"owner\":\n                sentence += f\"is owned by {object_value}. \"\n            elif predicate == \"shipBeam\":\n                sentence += f\"has a beam of {object_value}. \"\n            elif predicate == \"shipInService\":\n                sentence += f\"entered service on {object_value}. \"\n            elif predicate == \"status\":\n                sentence += f\"is currently {object_value}. \"\n            elif predicate == \"activeYearsStartDate\":\n                sentence += f\"started its active years in {object_value}. \"\n            elif predicate == \"shipLaidDown\":\n                sentence += f\"was laid down on {object_value}. \"\n            elif predicate == \"buildDate\":\n                sentence += f\"was built between {object_value}. \"\n            elif predicate == \"cylinderCount\":\n                sentence += f\"has {object_value} cylinders. \"\n            elif predicate == \"totalProduction\":\n                sentence += f\"had a total production of {object_value}. \"\n            elif predicate == \"countryOrigin\":\n                sentence += f\"originated from {object_value}. \"\n            elif predicate == \"diameter\":\n                sentence += f\"has a diameter of {object_value}. \"\n            elif predicate == \"failedLaunches\":\n                sentence += f\"had {object_value} failed launches. \"\n            elif predicate == \"rocketStages\":\n                sentence += f\"has {object_value} rocket stages. \"\n            elif predicate == \"totalLaunches\":\n                sentence += f\"had a total of {object_value} launches. \"\n            elif predicate == \"assembly\":\n                sentence += f\"was assembled in {object_value}. \"\n            elif predicate == \"class\":\n                sentence += f\"is a {object_value}. \"\n            elif predicate == \"designer\":\n                sentence += f\"was designed by {object_value}. \"\n            elif predicate == \"modelYears\":\n                sentence += f\"was produced in {object_value}. \"\n            elif predicate == \"country\":\n                sentence += f\"is in {object_value}. \"\n            elif predicate == \"foundationPlace\":\n                sentence += f\"was founded in {object_value}. \"\n            elif predicate == \"foundedBy\":\n                sentence += f\"was founded by {object_value}. \"\n            elif predicate == \"designCompany\":\n                sentence += f\"was designed by {object_value}. \"\n            elif predicate == \"productionStartYear\":\n                sentence += f\"started production in {object_value}. \"\n            elif predicate == \"width\":\n                sentence += f\"has a width of {object_value}. \"\n            elif predicate == \"layout\":\n                sentence += f\"has a {object_value} layout. \"\n            elif predicate == \"parentCompany\":\n                sentence += f\"is a subsidiary of {object_value}. \"\n            elif predicate == \"operator\":\n                sentence += f\"is operated by {object_value}. \"\n            elif predicate == \"product\":\n                sentence += f\"produces {object_value}. \"\n            elif predicate == \"city\":\n                sentence += f\"is located in {object_value}. \"\n            elif predicate == \"successor\":\n                sentence += f\"was succeeded by {object_value}. \"\n            elif predicate == \"fate\":\n                sentence += f\"became {object_value}. \"\n            elif predicate == \"keyPerson\":\n                sentence += f\"was led by {object_value}. \"\n            elif predicate == \"subsidiary\":\n                sentence += f\"has a subsidiary {object_value}. \"\n            elif predicate == \"comparable\":\n                sentence += f\"is comparable to {object_value}. \"\n            elif predicate == \"finalFlight\":\n                sentence += f\"had its final flight on {object_value}. \"\n            elif predicate == \"function\":\n                sentence += f\"functions as {object_value}. \"\n            elif predicate == \"launchSite\":\n                sentence += f\"launches from {object_value}. \"\n            elif predicate == \"maidenFlight\":\n                sentence += f\"had its maiden flight on {object_value}. \"\n            elif predicate == \"capital\":\n                sentence += f\"has a capital of {object_value}. \"\n            elif predicate == \"demonym\":\n                sentence += f\"its people are known as {object_value}. \"\n            elif predicate == \"leader\":\n                sentence += f\"is led by {object_value}. \"\n            elif predicate == \"partialFailures\":\n                sentence += f\"had {object_value} partial failures. \"\n            elif predicate == \"site\":\n                sentence += f\"is located at {object_value}. \"\n            elif predicate == \"headquarter\":\n                sentence += f\"is headquartered in {object_value}. \"\n            elif predicate == \"associatedRocket\":\n                sentence += f\"is associated with {object_value}. \"\n            elif predicate == \"saint\":\n                sentence += f\"is the patron saint of {object_value}. \"\n            elif predicate == \"employer\":\n                sentence += f\"was employed by {object_value}. \"\n            elif predicate == \"ethnicGroup\":\n                sentence += f\"includes {object_value}. \"\n            elif predicate == \"language\":\n                sentence += f\"speaks {object_value}. \"\n            elif predicate == \"leaderTitle\":\n                sentence += f\"has a leader with the title of {object_value}. \"\n            elif predicate == \"anthem\":\n                sentence += f\"has an anthem of {object_value}. \"\n            elif predicate == \"productionEndYear\":\n                sentence += f\"ended production in {object_value}. \"\n            elif predicate == \"division\":\n                sentence += f\"has a division {object_value}. \"\n            elif predicate == \"shipDraft\":\n                sentence += f\"has a draft of {object_value}. \"\n            elif predicate == \"modelStartYear\":\n                sentence += f\"started production in {object_value}. \"\n        \n    return sentence\n>>>>>>> REPLACE\n```"]}}, "artifacts_json": "{\"poor_program_score_448\": \"The program did very poorly with BLEU score 0.07304189954852412. The input triples were:\\nMid-Atlantic Regional Spaceport Launch Pad 0 | associatedRocket | Minotaur V\\nAntares (rocket) | comparable | Delta II\\nDelta II | countryOrigin | United States\\nAntares (rocket) | launchSite | Mid-Atlantic Regional Spaceport Launch Pad 0\\nThe generated text was:\\nMid-Atlantic Regional Spaceport Launch Pad 0 is associated with Minotaur V. \\nThe example correct sentences are:\\nThe Delta II rocket is from the United States and us similar to the Antares rocket, the launch site of which, was the Mid-Atlantic Regional Spaceport Launch Pad 0 which happens to be associated with the Minotaur V rocket.\\nThe Antares rocket is similar to the Delta II rocket, which originates from the United States. Both the Antares and the Minotaur V were launched from the Mid-Atlantic Regional Spaceport Launch Pad 0.\\n\", \"poor_program_score_585\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nGermany | leader | Norbert Lammert\\nGermany | demonym | Germans\\nNeptun Werft | city | Rostock\\nRostock | country | Germany\\nA-Rosa Luna | builder | Neptun Werft\\nThe generated text was:\\nGermany is led by Norbert Lammert. \\nThe example correct sentences are:\\nThe A-Rosa Luna was built by Neptun Werft, a company located in Rostock, Germany. Norbert Lammert is a leader in Germany and the people that live in the country are called Germans.\\nA-Rosa Luna was built by Neptun Werft in Rostock, Germany, where the leader is Norbert Lammert and the people are called Germans.\\n\", \"poor_program_score_495\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAleksey Chirikov (icebreaker) | builder | Finland\\nAleksey Chirikov (icebreaker) | length | 99.83\\nAleksey Chirikov (icebreaker) | shipBeam | 21.2\\nAleksey Chirikov (icebreaker) | builder | Helsinki\\nAleksey Chirikov (icebreaker) | powerType | W\\u00e4rtsil\\u00e4\\nThe generated text was:\\nAleksey Chirikov (icebreaker) was built by Finland. \\nThe example correct sentences are:\\nFinland in Helsinki is the manufacturer of the Aleksey Chirikov icebreaker which is W\\u00e4rtsil\\u00e4 powered. The icebreaker is 99.83 m long and has a ship beam of 21.2 m.\\nThe icebreaker Aleksey Chirikov was built in Helsinki, Finland and its powertype is Wartsila. It is 99.83 metres in length and has a ship beam of 21.2.\\nThe icebreaker, Aleksey Chirikov, powered by W\\u00e4rtsil\\u00e4, was built in Helsinki, Finland. It has a length of 99.83 and a 21.2m ship beam.\\n\", \"poor_program_score_159\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nUnited States | demonym | Americans\\nAtlas II | countryOrigin | United States\\nThe generated text was:\\nUnited States its people are known as Americans. \\nThe example correct sentences are:\\nThe Atlas II comes from the United States where Americans live.\\nAmericans live in the U.S, the home of The Atlas II.\\nPeople from the US are called Americans and Atlas II is from the United States.\\n\", \"poor_program_score_655\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAMC Matador | alternativeName | \\\"VAM Classic\\\"\\nAMC Matador | assembly | Thames, New Zealand\\nAMC Matador | bodyStyle | Station wagon\\nAMC Matador | engine | AMC V8 engine\\nThe generated text was:\\nAMC Matador is also known as \\\"VAM Classic\\\". \\nThe example correct sentences are:\\nThe AMC Matador has a station wagon style body and is equipped with an AMC V8 engine. Its alternative name is VAM Classic and it is assembled in Thames, New Zealand.\\nThe AMC Matador, alternatively known as the VAM Classic, is assembled in Thames, New Zealand. It has a station wagon body style and is equipped with an AMC V8 engine.\\nThe AMC Matador has a AMC V8 engine and a station wagon style body. It has an alternative name of the VAM Classic and was assembled in Thames, New Zealand.\\n\", \"poor_program_score_365\": \"The program did very poorly with BLEU score 0.09006726938226924. The input triples were:\\nAlhambra | owner | P&O (company)\\nP&O (company) | location | London\\nAlhambra | powerType | Humphrys, Tennant and Dykes\\nAlhambra | builder | Samuda Brothers\\nThe generated text was:\\nAlhambra is owned by P&O (company). \\nThe example correct sentences are:\\nThe Alhambra was built by the Samuda Brothers and has a Humphrys, Tennant and Dykes power type. It is owned by the P&O company located in London.\\nThe Alhambra, built by the Samuda Brothers, is powered by a Humphrys, Tennant and Dykes engine and belongs to the P & O transporting company located in London.\\nThe Alhambra is owned by P&O who are located in London. It was built by the Samuda Brothers and is powered by a Humphrys, Tennant and Dykes engine.\\n\", \"poor_program_score_343\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAcura TLX | class | Mid-size car\\nAcura TLX | assembly | Marysville Auto Plant\\nAcura TLX | layout | \\\"front-wheel drive / all-wheel drive\\\"\\nAcura TLX | engine | Honda K engine\\nThe generated text was:\\nAcura TLX is a Mid-size car. \\nThe example correct sentences are:\\nThe Acura TLX, which is assembled at the Marysville Auto Plant, has front-wheel and all-wheel drive, a Honda K engine and is a mid-size class of car.\\nClassed as a mid-size car, the Acura TLX has its assembly line at the Marysville Auto Plant. The Acura TLX has a Honda K engine and has front-wheel and all-wheel drive.\\nThe mid-size Acura TLX, made at the Marysville Auto Plant, has a Honda K engine and is front-wheel and all-wheel drive.\\n\", \"poor_program_score_641\": \"The program did very poorly with BLEU score 0.0538140946637381. The input triples were:\\nArgentina | capital | Buenos Aires\\nArgentina | leader | Mauricio Macri\\nARA Veinticinco de Mayo (V-2) | country | Argentina\\nThe generated text was:\\nArgentina has a capital of Buenos Aires. \\nThe example correct sentences are:\\nThe ARA Veinticinco De mayo (V-2) comes from the country of Argentina which is led by Mauricio Macri and has the capital city of Buenos Aires.\\nThe ARA Veinticinco de Mayo (V-2) comes from Argentina. Argentina's capital is Buenos Aires and its leader is Mauricio Macri.\\nARA Veinticinco de Mayo (V-2) comes from Argentina, where the capital is Buenos Aires and Mauricio Macri is the leader.\\n\", \"poor_program_score_411\": \"The program did very poorly with BLEU score 0.041213897603013756. The input triples were:\\nAtlas II | diameter | 3.04 m\\nAtlas II | finalFlight | 1998-03-16\\nAtlas II | launchSite | Vandenberg Air Force Base\\nAtlas II | launchSite | Cape Canaveral Air Force Station\\nThe generated text was:\\nAtlas II has a diameter of 3.04 m. \\nThe example correct sentences are:\\nThe Atlas II was launched from Vandenberg Air Force Base at Cape Canaveral. It is 3.04 m in diameter and its final flight was on 1998-03-16.\\nAtlas II was launched from Vandenberg Air Force Base and at the Cape Canaveral Air Force Station. It is 3.04 m in diameter and its last flight took place on March 16, 1998.\\nThe Atlas II was launched from Vandenberg Air Force Base and Cape Canaveral Air Force Station. It had a diameter of 3.04 m and made its final flight on 16 March 1998.\\n\", \"poor_program_score_463\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nUnited States | ethnicGroup | White Americans\\nALV X-1 | countryOrigin | United States\\nUnited States | demonym | Americans\\nUnited States | capital | Washington, D.C.\\nThe generated text was:\\nUnited States includes White Americans. \\nThe example correct sentences are:\\nALV X-1 comes from the US whose capital is in Washington, D.C. Americans live in that country as well as White Americans who are considered an ethnic group in the U.S.\\nAmericans live in the United States and white Americans are an ethnic group found within the United States. The ALV X-1 originated in the United States where the capital city is Washington, D.C.\\nThe country of origin of the ALV X-1 is the United States where the capital is Washington D.C. and white Americans are an ethnic group. The people of the United States are known as Americans.\\n\", \"poor_program_score_511\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAlhambra | shipBeam | 8.3 m\\nAlhambra | builder | Samuda Brothers\\nAlhambra | length | 63800.0 (millimetres)\\nAlhambra | status | \\\"Wrecked\\\"\\nAlhambra | topSpeed | 18.52\\nThe generated text was:\\nAlhambra has a beam of 8.3 m. \\nThe example correct sentences are:\\nThe Alhambra, which had wrecked, was built by the Samuda Brothers. It was 63800.0 millimetres long has a ship beam of 8.3m. It had a top speed of 18.52 km/h.\\nBefore it wrecked, the Alhambra was built by the Samuda Brothers. It had a length of 63800.0 mms, a top speed of 18.52 and a ship beam of 8.3 metres.\\n\", \"poor_program_score_200\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAbarth 1000 GT Coup\\u00e9 | wheelbase | 2160.0 (millimetres)\\nAbarth 1000 GT Coup\\u00e9 | bodyStyle | \\\"Two door coup\\u00e9\\\"\\nAbarth 1000 GT Coup\\u00e9 | engine | Straight-four engine\\nThe generated text was:\\nAbarth 1000 GT Coup\\u00e9 has a wheelbase of 2160.0 (millimetres). \\nThe example correct sentences are:\\nThe two door Abarth 1000 GT Coupe, with a straight four engine, has a 2160 millimeter wheelbase.\\nThe Abarth 1000 GT Coupe has the straight four engine, a wheel base of 2160 millimetres, and a 2 door coupe body style.\\nThe Abarth 1000 GT Coupe is a two door model with a straight-four engine and a 2160 mm wheelbase.\\n\", \"poor_program_score_189\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nALV X-1 | countryOrigin | United States\\nUnited States | ethnicGroup | Asian Americans\\nUnited States | capital | Washington, D.C.\\nThe generated text was:\\nALV X-1 originated from United States. \\nThe example correct sentences are:\\nALV X-1 hails comes from the U.S. where the capital is Washington, D.C. Asian Americans are an ethnic group in that country.\\nThe United States, with its capital in Washington D.C., is home to Asian Americans and the origin of ALV X-1.\\nALV X-1 comes from the US where Washington DC is the capital and Asian Americans are an ethnic group.\\n\", \"poor_program_score_326\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nALV X-1 | countryOrigin | United States\\nUnited States | ethnicGroup | Asian Americans\\nUnited States | demonym | Americans\\nUnited States | capital | Washington, D.C.\\nThe generated text was:\\nALV X-1 originated from United States. \\nThe example correct sentences are:\\nThe U.S. is the originator of the ALVX-1. Washington, D.C. is its capital, Americans live there, and one ethnic group is called the Asian Americans.\\nFound in the US is the ALV X-1. The capital of that country is Washington, D.C. and an ethnic group there is called Asian Americans. Americans occupy the U.S.\\nThe country of origin of the ALV X-1 is the United States which has the capital of Washington D.C. The inhabitants of the United States are called Americans but Asian Americans are one of the ethnic groups there.\\n\", \"poor_program_score_709\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nPontiac Rageous | productionStartYear | 1997\\nPontiac Rageous | productionEndYear | 1997\\nPontiac Rageous | bodyStyle | Coupe\\nPontiac Rageous | manufacturer | Pontiac\\nThe generated text was:\\nPontiac Rageous started production in 1997. \\nThe example correct sentences are:\\nThe Pontiac Rageous was a car with a coupe body style that was manufactured by Pontiac, first produced in 1997 and last produced in 1997 as well.\\nThe Pontiac Rageous which has a coupe body style was manufactured by Pontiac only in 1997.\\nThe coupe, the Pontiac Rageous, was first and last made in 1997 by Pontiac.\\n\", \"poor_program_score_631\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nA-Rosa Luna | shipClass | Cruise ship\\nA-Rosa Luna | length | 125800.0 (millimetres)\\nA-Rosa Luna | shipOrdered | 2004-01-22\\nThe generated text was:\\nA-Rosa Luna is a Cruise ship. \\nThe example correct sentences are:\\nOrdered on January 22nd, 2004, the A-Rosa Luna, is classed as a Cruise ship and has a length of 125.8 metres.\\nA-Rosa Luna, a cruise ship 125800.0 millimetres in length, was ordered on January 22, 2004.\\n\", \"poor_program_score_4\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nA-Rosa Luna | shipLaunch | 2004-12-16\\nThe generated text was:\\nA-Rosa Luna was launched on 2004-12-16. \\nThe example correct sentences are:\\nDecember 16, 2004 was the launch date for the A-Rosa Luna ship.\\nThe ship A-Rosa Luna's launch date was the 16th December 2004.\\n\", \"poor_program_score_108\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nALV X-1 | countryOrigin | United States\\nUnited States | ethnicGroup | Native Americans in the United States\\nThe generated text was:\\nALV X-1 originated from United States. \\nThe example correct sentences are:\\nALV X-1 hails from the US, where there is an ethnic group called Native Americans.\\nThe ALV X-1 came from the United States, a country where Native Americans are an ethnic group.\\nALV X-1 originated in the United States where Native Americans are one of the ethnic groups.\\n\", \"poor_program_score_149\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAudi A1 | engine | 1.2 (litres)\\nAudi A1 | bodyStyle | Hatchback\\nThe generated text was:\\nAudi A1 is powered by a 1.2 (litres). \\nThe example correct sentences are:\\nThe Audi A1 is a hatchback with a 1.2 litre engine.\\nThe Audi A1 is a hatchback and has a 1.2 litre engine.\\n\", \"poor_program_score_256\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAudi A1 | engine | 1.2 (litres)\\nAudi A1 | transmission | \\\"5-speed manual\\\"\\nAudi A1 | assembly | Audi Brussels\\nThe generated text was:\\nAudi A1 is powered by a 1.2 (litres). \\nThe example correct sentences are:\\nAudi A1 has a 1.2 litre engine and a 5-speed manual transmission. It is assembled by Audi Brussels.\\nThe Audi A1, assembled in Audi Brussels, has a 5-speed manual transmission and a 1.2 liter engine.\\nThe Audi A1, produced by Audi Brussels, has a 1.2 l engine and a 5 speed manual transmission.\\n\", \"poor_program_score_702\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nALCO RS-3 | cylinderCount | 12\\nALCO RS-3 | builder | Montreal Locomotive Works\\nThe generated text was:\\nALCO RS-3 has 12 cylinders. \\nThe example correct sentences are:\\nMontreal Locomotive Works is the builder of the 12 cylinder ALCO RS-3.\\nBuilt by Montreal Locomotive Works, the ALCO RS-3 has a cylinder count of 12.\\nThe 12 cylinder ALCO RS-3 was built by the Montreal Locomotive Works.\\n\", \"poor_program_score_59\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nDeSoto Custom | successor | DeSoto Firedome\\nThe generated text was:\\nDeSoto Custom was succeeded by DeSoto Firedome. \\nThe example correct sentences are:\\nThe Desoto Custom's successor is the DeSoto Firedome.\\nThe DeSoto Firedome was preceded by the DeSoto Custom.\\nThe successor of the DeSoto Custom automobile was the DeSoto Firedome.\\n\", \"poor_program_score_460\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nUnited States | ethnicGroup | Asian Americans\\nUnited States | demonym | Americans\\nAtlas II | countryOrigin | United States\\nUnited States | leaderTitle | President of the United States\\nThe generated text was:\\nUnited States includes Asian Americans. \\nThe example correct sentences are:\\nThe Atlas II originates from the United States which is led by the President. The country's inhabitants are called Americans and include the ethnic group of Asian Americans.\\nThe Atlas II originated from the U.S, where Americans live and Asian Americans are one of the ethnic groups. The title of the leader of United States is The President of the United States.\\nAtlas II originates from the United States, where Americans live and Asian Americans are one of the ethnic groups. The leader of the United States has the title President of the United States.\\n\", \"poor_program_score_57\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAudi A1 | relatedMeanOfTransportation | Volkswagen Polo\\nThe generated text was:\\nAudi A1 is related to Volkswagen Polo. \\nThe example correct sentences are:\\nThe Audi A1 and Volkswagen Polo are related kinds of transportation.\\nThe Audi A1 is a related vehicle to the VW Polo.\\n\", \"poor_program_score_719\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nPontiac | extinctionDate | 2010-10-31\\nThe generated text was:\\nPontiac \\nThe example correct sentences are:\\nThe Pontiac brand became extinct on October 31, 2010.\\nPontiac went extinct on 2010-10-31.\\n\", \"poor_program_score_171\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nA-Rosa Luna | shipDisplacement | 1850.0 (tonnes)\\nA-Rosa Luna | builder | \\\"Neptun Werft, Warnem\\u00fcnde,\\\"\\nA-Rosa Luna | length | 125800.0 (millimetres)\\nThe generated text was:\\nA-Rosa Luna has a displacement of 1850.0 (tonnes). \\nThe example correct sentences are:\\nThe A-Rosa Luna, built by Neptun Werft, Warnem\\u00fcnde has a 1850 ton displacement and length of 125800.0 mm.\\nThe A-Rosa Luna; was built by Neptun Werft, Warnem\\u00fcnde, weighs 1850 tonnes and is 125.8 metres long.\\nThe A Rosa Luna is 125.8m long and has a ship displacement of 1850 tonnes. It was built by Neptun Werft in Warnemunde.\\n\", \"poor_program_score_210\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAleksey Chirikov (icebreaker) | builder | Finland\\nAleksey Chirikov (icebreaker) | shipBeam | 21.2\\nAleksey Chirikov (icebreaker) | builder | Helsinki\\nThe generated text was:\\nAleksey Chirikov (icebreaker) was built by Finland. \\nThe example correct sentences are:\\nThe icebreaker, Aleksey Chirikov, built by Finland, has a ship beam of 21.2m, and the builder is in Helsinki.\\nThe icebreaker Aleksey Chirikov, built in Helsinki, Finland, has a 21.2 m ship beam.\\nIcebreaker Aleksey Chirikov, built by Aleksey Chirikov in Helsinki, Finland, has a 21.2 length ship beam.\\n\", \"poor_program_score_615\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAlhambra | shipBeam | 8.3 m\\nThe generated text was:\\nAlhambra has a beam of 8.3 m. \\nThe example correct sentences are:\\nThe Alhambra ship beam is 8.3m.\\nThe Alhambra has a ship beam of 8.3m.\\nThe Alhambra has an 8.3m ship beam.\\n\", \"poor_program_score_177\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAIDAluna | maidenVoyage | 2009-03-22\\nAIDAluna | shipBeam | 32.2\\nAIDAluna | length | 252000.0 (millimetres)\\nThe generated text was:\\nAIDAluna had its maiden voyage on 2009-03-22. \\nThe example correct sentences are:\\nWith its premier trip on March 22, 2009, the AIDAluna is 252000.0 millimetres long and has a ship beam of 32.2 long.\\nThe AIDAluna has a length of 252000.0 millimetres and a beam of 32.2m. It made its first trip on March 22, 2009.\\nThe AIDAluna is 252m long and has a beam of 32.2m. Her maiden voyage was on March 22nd 2009.\\n\", \"poor_program_score_352\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAleksey Chirikov (icebreaker) | builder | Finland\\nFinland | demonym | Finns\\nAleksey Chirikov (icebreaker) | builder | Helsinki\\nFinland | leader | Sauli Niinist\\u00f6\\nThe generated text was:\\nAleksey Chirikov (icebreaker) was built by Finland. \\nThe example correct sentences are:\\nThe icebreaker, Aleksey Chirikov, was made in Helsinki, Finland. The leader in Finland is Sauli Niinist\\u00f6 and the people there are Finns.\\nThe icebreaker Aleksey Chirikov was built in Helsinki, Finland. The country, whose people are known as Finns, is led by Sauli Niinisto.\\n\", \"poor_program_score_592\": \"The program did very poorly with BLEU score 0.07603512141930886. The input triples were:\\nUnited States | capital | Washington, D.C.\\nAtlas II | countryOrigin | United States\\nUnited States | ethnicGroup | African Americans\\nAtlas II | launchSite | Vandenberg Air Force Base\\nVandenberg Air Force Base | location | Lompoc, California\\nThe generated text was:\\nUnited States has a capital of Washington, D.C.. \\nThe example correct sentences are:\\nAtlas II was launched from Vandenberg Air Force Base, located in Lompoc, California, and originated from the U.S. Washington D.C. is the capital city of the United States and one of its ethnic groups is African Americans.\\nThe Atlas II, which was launched from Vandenberg Air Force Base located in Lompoc, California, originates from the United States. The capital of the United States is Washington, D.C. and one of its ethnic groups is African Americans.\\nThe Atlas II launched from Vandenberg Air Force base located at Lompoc, California. It originates from the United States where the capital city is Washington DC and the African Americans are an ethnic group.\\n\", \"poor_program_score_145\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAtlas II | countryOrigin | United States\\nAtlas II | launchSite | Vandenberg Air Force Base\\nThe generated text was:\\nAtlas II originated from United States. \\nThe example correct sentences are:\\nAtlas II originates from the United States and was launched from Vandenberg Air Force Base.\\nThe Atlas II originates from the United States and launched from Vandenberg Air Force Base.\\nAtlas II from the United States, was launched from Vandenberg Air Force Base.\\n\", \"poor_program_score_484\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nALCO RS-3 | builder | American Locomotive Company\\nALCO RS-3 | length | 17068.8 (millimetres)\\nALCO RS-3 | buildDate | \\\"May 1950 - August 1956\\\"\\nALCO RS-3 | engine | Four-stroke engine\\nALCO RS-3 | powerType | Diesel-electric transmission\\nThe generated text was:\\nALCO RS-3 was built by American Locomotive Company. \\nThe example correct sentences are:\\nBuilt by the American Locomotive Company, the ALCO RS-3 was produced between May 1950 and August 1956. The ALCO RS-3; has a diesel-electric transmission, a four-stroke engine and is 17068.8 millimetres long.\\nThe builder of the ALCO RS-3 is the American Locomotive Company and it was produced between May 1950 and August 1956. The length of ALCO RS-3 is 17068.8 millimetres, it has a four-stroke engine and a diesel-electric transmission.\\nThe American Locomotive Company built the ALCO RS-3 and it was produced between May 1950 and August 1956. The length of ALCO RS-3 is 17068.8 millimetres, it has a four-stroke engine and a diesel-electric transmission.\\n\", \"poor_program_score_587\": \"The program did very poorly with BLEU score 0.05013190407229487. The input triples were:\\nGuiana Space Centre | location | French Guiana\\nGuiana Space Centre | headquarter | Kourou, French Guiana\\nELA-3 | site | Guiana Space Centre\\nAriane 5 | launchSite | ELA-3\\nELA-3 | operator | Arianespace\\nThe generated text was:\\nGuiana Space Centre is located in French Guiana. \\nThe example correct sentences are:\\nThe Guiana Space Centre, located in French Guiana, has its headquarters located in Kourou. It is the site of ELA-3 launchpad which is operated by Arianespace and is the launch site of the Ariane 5.\\nThe ELA-3, where The Ariane 5 was launched, is operated by Arianespace. The site of ELA-3 is at the Guiana Space Centre, whose headquarters are in Kourou, French Guiana.\\nThe Ariane 5 was launched at the ELA-3 which is operated by Arianespace and located at the Guiana Space Centre which has its HQ at Kourou, French Guiana.\\n\", \"poor_program_score_591\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nUnited Kingdom | leader | Elizabeth II\\nAston Martin V8 | relatedMeanOfTransportation | Aston Martin RHAM/1\\nAston Martin V8 | assembly | United Kingdom\\nAston Martin V8 | successor | Aston Martin Virage\\nAston Martin Virage | manufacturer | Aston Martin\\nThe generated text was:\\nUnited Kingdom is led by Elizabeth II. \\nThe example correct sentences are:\\nAston Martin manufactured the Aston Martin Virage which succeeded the Aston Martin V8. The latter vehicle is a related means of transport to the Aston Martin RHAM/1 and assembled in the United Kingdom which is ruled by Queen Elizabeth II.\\nThe Aston Martin V8, made in the, Queen Elizabeth II led, U.K., is relative to the Aston Martin RHAM/1 and succeeded by the Aston Martin Virage (Aston Martin).\\nThe Aston Martin V8, assembled in the U.K. (led by Queen Elizabeth II), is relative to the Aston Martin RHAM/1 and its successor, the Aston Martin Virage (manufactured by Aston Martin).\\n\", \"poor_program_score_70\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nHonda Accord | manufacturer | Honda\\nThe generated text was:\\nHonda Accord is manufactured by Honda. \\nThe example correct sentences are:\\nThe Honda Accord is made by Honda.\\nHonda is the manufacturer of the Honda Accord.\\nHonda manufactures a model called the Accord.\\n\", \"poor_program_score_372\": \"The program did very poorly with BLEU score 0.09318905723212921. The input triples were:\\nAlvis Speed 25 | manufacturer | Alvis Car and Engineering Company\\nAlvis Car and Engineering Company | foundationPlace | Coventry\\nAlvis Speed 25 | engine | 4387.0 (cubicCentimetres)\\nAlvis Car and Engineering Company | successor | Rover Company\\nThe generated text was:\\nAlvis Speed 25 is manufactured by Alvis Car and Engineering Company. \\nThe example correct sentences are:\\nThe Alvis Car and Engineering Company, which was founded in Coventry and later succeeded by the Rover Company, manufactured the Alvis Speed 25 that has a 4387.00 cc engine.\\nThe Alvis Speed 25 was manufactured by the Alvis Car and Engineering Company which was founded in Coventry and succeeded by the Rover Company. It has an engine of 4387 cubic centimetres.\\nThe Alvis Speed 25, which has a 4387.00 cc engine, was made by the Alvis Car and Engineering Company which was founded in Coventry and succeeded by The Rover Co.\\n\", \"poor_program_score_155\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nDeSoto Custom | relatedMeanOfTransportation | Dodge Coronet\\n1955 Dodge | relatedMeanOfTransportation | DeSoto Custom\\nThe generated text was:\\nDeSoto Custom is related to Dodge Coronet. \\nThe example correct sentences are:\\nThe 1955 Dodge, the DeSoto Custom, and the Dodge Coronet are similar and therefore related means of transport.\\nThe DeSoto is related to the Dodge Coronet, and the 1955 Dodge and the DeSoto Custom are related means of transportation.\\nThe 1955 Dodge, DeSoto Custom and Dodge Coronet are all related.\\n\", \"poor_program_score_7\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAIDAluna | status | \\\"In service\\\"\\nThe generated text was:\\nAIDAluna is currently \\\"In service\\\". \\nThe example correct sentences are:\\nAIDAluna is in service.\\nThe AIDAluna is currently in service.\\n\", \"poor_program_score_694\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nPontiac Rageous | productionStartYear | 1997\\nPontiac Rageous | assembly | Michigan\\nPontiac Rageous | assembly | Detroit\\nPontiac Rageous | productionEndYear | 1997\\nPontiac Rageous | bodyStyle | Coupe\\nThe generated text was:\\nPontiac Rageous started production in 1997. \\nThe example correct sentences are:\\nThe Pontiac Rageous, a coupe assembled in Michigan, was first and last produced in 1997. It had its assembly line in Detroit.\\nThe Pontiac Rageous, a car with a coupe body style, assembled in Detroit Michigan, was first and last produced in 1997.\\nIn 1997, the Pontiac Rageous coupe (assembled in Detroit, Michigan) went into and ended production.\\n\", \"poor_program_score_291\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\n1955 Dodge | relatedMeanOfTransportation | DeSoto Custom\\nDodge | keyPerson | Sergio Marchionne\\nDeSoto Custom | relatedMeanOfTransportation | Chrysler Newport\\n1955 Dodge | manufacturer | Dodge\\nThe generated text was:\\n1955 Dodge is related to DeSoto Custom. \\nThe example correct sentences are:\\nThe 1955 Dodge the DeSoto Custom and Chrysler Newport are related means of transportation. The key person of Dodge is Sergio Marchionne.\\nThe DeSoto Custom is related to the 1955 Dodge, made by Dodge, who has a key person called Sergio Marchionne. The Desoto is related to the Chrysler Newport car.\\nDodge Co. made the 1955 Dodge car which is relative to the DeSoto Custom which in turn is similar to the Chrysler Newport car. Sergio Marchionne is an important person for Dodge Co.\\n\", \"poor_program_score_87\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\n1955 Dodge | relatedMeanOfTransportation | DeSoto Custom\\n1955 Dodge | manufacturer | Dodge\\nThe generated text was:\\n1955 Dodge is related to DeSoto Custom. \\nThe example correct sentences are:\\nThe Dodge manufactured, 1955 Dodge and the DeSoto Custom are related means of transportation.\\nThe 1955 Dodge, manufactured by Dodge, is a related means of transport to the DeSoto Custom.\\nThe Dodge 1955 is made by Dodge and is related to the Desoto Custom.\\n\", \"poor_program_score_718\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nALCO RS-3 | buildDate | \\\"May 1950 - August 1956\\\"\\nALCO RS-3 | powerType | Diesel-electric transmission\\nALCO RS-3 | length | 17068.8 (millimetres)\\nThe generated text was:\\nALCO RS-3 was built between \\\"May 1950 - August 1956\\\". \\nThe example correct sentences are:\\nThe ALCO RS-3, produced between May 1950 and August 1956, has a length of 17068.8 millimetres and a diesel-electric transmission.\\nThe ALCO RS-3 had a diesel-electric transmission, measured 17068.8 (millimetres) in length and was produced between May 1950 and August 1956.\\nALCO RS-3, which is 17068.8 millimetres long and has a diesel-electric transmission, was made between May 1950 and August 1956.\\n\", \"poor_program_score_643\": \"The program did very poorly with BLEU score 0.08047084086794415. The input triples were:\\nAtlas II | countryOrigin | United States\\nUnited States | ethnicGroup | Native Americans in the United States\\nUnited States | leaderTitle | President of the United States\\nThe generated text was:\\nAtlas II originated from United States. \\nThe example correct sentences are:\\nThe Atlas II comes from the US where Native Americans are an ethnic group and the leader is the President.\\nThe Atlas II originated from the United States, where Native Americans are an ethnic group. The leader of the United States has the title President of the United States.\\nThe Atlas II originated from the U.S. where the President is the leader and Native Americans are an ethnic group.\\n\", \"poor_program_score_332\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nAMC Matador | alternativeName | \\\"VAM Classic\\\"\\nAMC Matador | assembly | Thames, New Zealand\\nAMC Matador | bodyStyle | Coup\\u00e9\\nAMC Matador | engine | AMC V8 engine\\nThe generated text was:\\nAMC Matador is also known as \\\"VAM Classic\\\". \\nThe example correct sentences are:\\nThe AMC Matador is assembled in Thames, New Zealand and its alternative name is VAM Classic. The AMC Matador has a Coup\\u00e9 style body and is equipped with an AMC V8 engine.\\nThe Coup\\u00e9 AMC Matador, aka VAM Classic, is assembled in Thames, New Zealand, and has a AMC V8 engine.\\nThe AMC Matador, also known as VAM Classic, is assembled in Thames, New Zealand. It has a Coup\\u00e9 style body and has a AMC V8 engine.\\n\", \"poor_program_score_482\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nALCO RS-3 | builder | American Locomotive Company\\nALCO RS-3 | cylinderCount | 12\\nALCO RS-3 | engine | Four-stroke engine\\nALCO RS-3 | totalProduction | 1418\\nALCO RS-3 | length | 17068.8 (millimetres)\\nThe generated text was:\\nALCO RS-3 was built by American Locomotive Company. \\nThe example correct sentences are:\\nAmerican Locomotive Company built the 1418 ALCO RS-3s, which were 17068.8 (millimetres) in length, had 12 cylinders, and a four-stroke 12 cylinder engine.\\nThe American Locomotive Company produced the ALCO RS-3 which has a total of 12 cylinders, a four-stroke engine and is 17068.8 millimetres long. Only 1418 of that model were manufactured.\\nThe American Locomotive Company producted the ALCO RS-3 with its four-stroke engine and its 12 cylinders. The vehicle is 17068.8 (millimetres) in length and the company only made 1418 of them.\\n\", \"poor_program_score_294\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nA-Rosa Luna | shipDisplacement | 1850.0 (tonnes)\\nA-Rosa Luna | topSpeed | 24.0\\nA-Rosa Luna | length | 125800.0 (millimetres)\\nA-Rosa Luna | powerType | MTU Friedrichshafen\\nThe generated text was:\\nA-Rosa Luna has a displacement of 1850.0 (tonnes). \\nThe example correct sentences are:\\nThe A-Rosa Luna is powered by MTU Friedrichshafen made engines and its top speed is 24.0. It is 125800.0 millimetres in length and has a ship displacement of 1850 tonnes.\\nThe ship A-Rosa Luna weighs 1850 tonnes, has a top speed of 24.0, is 125800.0 millimetres in length, and is powered by a MTU Friedrichshafen engine.\\nThe A-Rosa Luna is powered by a MTU Friedrichshafen engine and has a top speed of, 24.0. It has a ship displacement of 1850 tonnes and a length of, 125.8 metres.\\n\", \"poor_program_score_708\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nPontiac Rageous | productionStartYear | 1997\\nPontiac Rageous | assembly | Michigan\\nPontiac Rageous | assembly | Detroit\\nPontiac Rageous | productionEndYear | 1997\\nPontiac Rageous | manufacturer | Pontiac\\nThe generated text was:\\nPontiac Rageous started production in 1997. \\nThe example correct sentences are:\\nThe Pontiac Rageous was a car manufactured by Pontiac. It went into production in 1997 and ended the same year. It was assembled in Detroit, Michigan.\\nThe Pontiac Rageous is manufactured by Pontiac and was first produced in 1997 in Detroit, Michigan. The Pontiac Rageous was also last produced in the same year.\\nThe Pontiac Rageous, manufactured by Pontiac, assembled in Detroit Michigan, was first and last produced in 1997.\\n\", \"poor_program_score_686\": \"The program did very poorly with BLEU score 0.012140576810398122. The input triples were:\\nDelta II | launchSite | Vandenberg Air Force Base\\nAntares (rocket) | comparable | Delta II\\nDelta II | countryOrigin | United States\\nAntares (rocket) | launchSite | Mid-Atlantic Regional Spaceport Launch Pad 0\\nMid-Atlantic Regional Spaceport Launch Pad 0 | associatedRocket | Minotaur IV\\nThe generated text was:\\nDelta II launches from Vandenberg Air Force Base. \\nThe example correct sentences are:\\nThe launch site of the rocket Antares was the Mid-Atlantic Regional Spaceport Launch Pad 0, which is associated with the Minotaur IV rocket. The Antares rocket is comparable with the Delta II, which originated from the United States, and was launched at Vandenberg Air Force Base.\\nThe Minotaur IV rocket and the Antares rocket were launched from the Mid-Atlantic Regional Spaceport Launch Pad 0. The latter rocket is comparable to the Delta II which originated in the United States and launched from the Vandenberg Air Force Base.\\n\", \"poor_program_score_282\": \"The program did very poorly with BLEU score 0.0. The input triples were:\\nUnited States | ethnicGroup | White Americans\\nALV X-1 | countryOrigin | United States\\nUnited States | capital | Washington, D.C.\\nThe generated text was:\\nUnited States includes White Americans. \\nThe example correct sentences are:\\nALV X-1 originated in the United States, where Washington D.C. is the capital city. It is also where White Americans are an ethnic group.\\nThe ALV X-1 originates from the United States which has the capital city of Washington DC and the white americans as an ethnic group.\\nALV X-1 originated in the United States. The country where, White Americans are an ethnic group and the capital is Washington D.C.\\n\"}", "artifact_dir": null, "embedding": null}