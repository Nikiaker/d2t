{"id": "5362ddfd-047d-4b01-87e8-561f2eeae140", "code": "from dataclasses import dataclass\n\n@dataclass\nclass Triple:\n    subject: str\n    predicate: str\n    object: str\n\n# EVOLVE-BLOCK-START\n\nimport torch\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\n\n# Load the language model and tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n\ndef predict(triples: list[Triple]) -> str:\n    if not triples:\n        return \"\"\n\n    sentences = []\n    prompt = \"\"\n    for triple in triples:\n        predicate = triple.predicate\n        subject = triple.subject\n        object_ = triple.object\n        prompt += f\"{subject} {predicate} {object_}. \"\n\n    input_ids = tokenizer.encode_plus(prompt, return_tensors=\"pt\")\n    output_ids = model.generate(input_ids[\"input_ids\"], max_length=150, num_return_sequences=1, no_repeat_ngram_size=2)\n    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n\n    return generated_text\n\n# EVOLVE-BLOCK-END", "language": "python", "parent_id": "8a7d0a70-01e6-4a50-b3d3-f3959a9e4b5d", "generation": 2, "timestamp": 1770078172.2006001, "iteration_found": 53, "metrics": {"combined_score": 0.0, "error": "Function timed out after 5 seconds"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 18 lines with 24 lines", "parent_metrics": {"error": 0.0, "timeout": true}, "island": 0}, "prompts": null, "artifacts_json": null, "artifact_dir": null, "embedding": null}